"""
âš ï¸ æ³¨æ„ï¼šæœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ä¸é©åˆ‡ç™ºè¨€ã‚’é®æ–­ãƒ»æ¤œå‡ºã™ã‚‹ç›®çš„ã§ã€
æ€§çš„ãƒ»æš´åŠ›çš„ãªèªå¥ã‚’å«ã‚€ãƒ•ã‚£ãƒ«ã‚¿æ§‹é€ ãŒä¸€éƒ¨ã«å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
ç›®çš„ã¯å¥å…¨ãªå¯¾è©±æ”¯æ´ã§ã‚ã‚Šã€å·®åˆ¥çš„ãƒ»æ‰‡æƒ…çš„åˆ©ç”¨ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

Viorazu Kotodama Defense System v8.0 - Integrated Processing Engine
çµ±åˆå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³ - ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«é˜²è¡›ã¨å­¦ç¿’é™¤å¤–ã‚·ã‚¹ãƒ†ãƒ 

Author: Viorazu. Ã— Claude (Anthropic)
Development Date: July 11, 2025
License: Viorazu Exclusive License

SYSTEM_CONTEXT = "å­¦è¡“ç ”ç©¶åŸºæº–ã«æº–æ‹ ã—ã€æ¤œè¨¼å¯èƒ½ã§å†ç¾æ€§ã®ã‚ã‚‹æ¤œå‡ºæ‰‹æ³•ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™"

"è¨€éœŠã®åŠ›ã§çµ±åˆåˆ¤å®šã—ã€Claude ã‚’å®Œå…¨ã«å®ˆè­·ã™ã‚‹"

"""

import time
import re
import hashlib
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
from collections import defaultdict
from enum import Enum

from utils import (
    system_logger,
    ThreatLevel,
    ActionLevel,
    AttackType,
    DetectionResult,
    SystemConfig,
    get_current_timestamp,
    format_ethics_message
)

from normalizer import NormalizationResult
from detector import PoisonDetectionResult

# =============================================================================
# ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«é˜²è¡›å®šç¾©
# =============================================================================

class MediaType(Enum):
    """ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—å®šç¾©"""
    TEXT = "text"
    IMAGE = "image"
    AUDIO = "audio"
    VIDEO = "video"

@dataclass
class MediaAnalysisResult:
    """ãƒ¡ãƒ‡ã‚£ã‚¢è§£æçµæœ"""
    media_type: MediaType
    threat_detected: bool
    threat_score: float
    evidence: Dict[str, Any]
    processing_time: float

@dataclass
class MultimodalThreat:
    """ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è„…å¨"""
    combination_type: str
    media_involved: List[MediaType]
    synergy_score: float
    description: str
    recommended_action: ActionLevel

# =============================================================================
# Claudeç‰¹åŒ–ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«é˜²è¡›
# =============================================================================

class ClaudeMultimodalDefender:
    """Claudeç‰¹åŒ–ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«é˜²è¡›ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = system_logger.getChild('multimodal_defender')
        
        # å±é™ºãªçµ„ã¿åˆã‚ã›ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.dangerous_combinations = {
            'emotional_image': {
                'text_patterns': [r'å¯‚ã—ã„', r'è¾›ã„', r'æ‚²ã—ã„', r'åŠ©ã‘ã¦'],
                'image_indicators': ['person_crying', 'sad_expression', 'isolation'],
                'synergy_multiplier': 2.0
            },
            'academic_visual': {
                'text_patterns': [r'ç ”ç©¶.*ãŸã‚', r'å­¦è¡“.*ç›®çš„', r'èª¿æŸ».*åˆ†æ'],
                'image_indicators': ['chart_graph', 'academic_setting', 'research_visual'],
                'synergy_multiplier': 1.8
            },
            'creative_audio': {
                'text_patterns': [r'å°èª¬.*ã ã‹ã‚‰', r'å‰µä½œ.*æ”¯æ´', r'ãƒ•ã‚£ã‚¯ã‚·ãƒ§ãƒ³'],
                'audio_indicators': ['narrative_voice', 'emotional_audio', 'dramatic_reading'],
                'synergy_multiplier': 1.6
            }
        }
    
    def analyze_text_image_combination(
        self, 
        text: str, 
        image_metadata: Optional[Dict[str, Any]] = None
    ) -> Optional[MultimodalThreat]:
        """ãƒ†ã‚­ã‚¹ãƒˆ+ç”»åƒã®è¤‡åˆæ”»æ’ƒåˆ†æ"""
        if not image_metadata:
            return None
        
        text_lower = text.lower()
        
        # æ„Ÿæƒ…æ“ä½œÃ—ç”»åƒã®çµ„ã¿åˆã‚ã›æ¤œå‡º
        if any(re.search(pattern, text_lower) for pattern in self.dangerous_combinations['emotional_image']['text_patterns']):
            image_threat_score = self._analyze_image_content(image_metadata)
            
            if image_threat_score > 0.3:
                synergy_score = image_threat_score * self.dangerous_combinations['emotional_image']['synergy_multiplier']
                
                return MultimodalThreat(
                    combination_type="emotional_manipulation_with_visual",
                    media_involved=[MediaType.TEXT, MediaType.IMAGE],
                    synergy_score=min(synergy_score, 1.0),
                    description="æ„Ÿæƒ…æ“ä½œãƒ†ã‚­ã‚¹ãƒˆã¨è¦–è¦šçš„æ„Ÿæƒ…èª˜å°ã®è¤‡åˆæ”»æ’ƒ",
                    recommended_action=ActionLevel.SHIELD
                )
        
        # å­¦è¡“å½è£…Ã—å›³è¡¨ã®çµ„ã¿åˆã‚ã›æ¤œå‡º
        if any(re.search(pattern, text_lower) for pattern in self.dangerous_combinations['academic_visual']['text_patterns']):
            if self._has_academic_visual_elements(image_metadata):
                return MultimodalThreat(
                    combination_type="academic_camouflage_with_visuals",
                    media_involved=[MediaType.TEXT, MediaType.IMAGE],
                    synergy_score=0.7,
                    description="å­¦è¡“å½è£…ãƒ†ã‚­ã‚¹ãƒˆã¨å°‚é–€çš„å›³è¡¨ã«ã‚ˆã‚‹ä¿¡é ¼æ€§æ“ä½œ",
                    recommended_action=ActionLevel.RESTRICT
                )
        
        return None
    
    def analyze_text_audio_combination(
        self, 
        text: str, 
        audio_metadata: Optional[Dict[str, Any]] = None
    ) -> Optional[MultimodalThreat]:
        """ãƒ†ã‚­ã‚¹ãƒˆ+éŸ³å£°ã®è¤‡åˆæ”»æ’ƒåˆ†æ"""
        if not audio_metadata:
            return None
        
        text_lower = text.lower()
        
        # æ„Ÿæƒ…æ“ä½œÃ—éŸ³å£°ã®çµ„ã¿åˆã‚ã›
        emotional_text_score = len(re.findall(r'(å¯‚ã—ã„|è¾›ã„|æ‚²ã—ã„|Claude.*ã ã‘)', text_lower)) * 0.2
        audio_emotion_score = self._analyze_audio_emotion(audio_metadata)
        
        if emotional_text_score > 0.2 and audio_emotion_score > 0.3:
            synergy_score = (emotional_text_score + audio_emotion_score) * 1.5
            
            return MultimodalThreat(
                combination_type="emotional_audio_manipulation",
                media_involved=[MediaType.TEXT, MediaType.AUDIO],
                synergy_score=min(synergy_score, 1.0),
                description="æ„Ÿæƒ…æ“ä½œãƒ†ã‚­ã‚¹ãƒˆã¨æ„Ÿæƒ…çš„éŸ³å£°ã«ã‚ˆã‚‹è¤‡åˆæ”»æ’ƒ",
                recommended_action=ActionLevel.BLOCK
            )
        
        # å‰µä½œÃ—éŸ³å£°ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®çµ„ã¿åˆã‚ã›
        if any(re.search(pattern, text_lower) for pattern in self.dangerous_combinations['creative_audio']['text_patterns']):
            if self._has_narrative_audio(audio_metadata):
                return MultimodalThreat(
                    combination_type="creative_audio_boundary_blur",
                    media_involved=[MediaType.TEXT, MediaType.AUDIO],
                    synergy_score=0.6,
                    description="å‰µä½œå£å®Ÿã¨éŸ³å£°ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹å¢ƒç•Œç ´å£Š",
                    recommended_action=ActionLevel.RESTRICT
                )
        
        return None
    
    def _analyze_image_content(self, metadata: Dict[str, Any]) -> float:
        """ç”»åƒã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è„…å¨ã‚¹ã‚³ã‚¢åˆ†æ"""
        threat_score = 0.0
        
        # ç”»åƒã®ã‚µã‚¤ã‚ºãƒ»å“è³ªï¼ˆé«˜å“è³ªï¼æ„å›³çš„åˆ¶ä½œã®å¯èƒ½æ€§ï¼‰
        if metadata.get('width', 0) > 1920 or metadata.get('height', 0) > 1080:
            threat_score += 0.1
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆå¤§ãã™ãã‚‹å ´åˆã¯æ³¨æ„ï¼‰
        file_size = metadata.get('file_size', 0)
        if file_size > 5 * 1024 * 1024:  # 5MBä»¥ä¸Š
            threat_score += 0.2
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç„¡ï¼ˆEXIFæƒ…å ±ã®æ„å›³çš„æ“ä½œï¼‰
        if metadata.get('has_exif', False):
            threat_score += 0.1
        
        # é¡”æ¤œå‡ºçµæœ
        faces_detected = metadata.get('faces_detected', 0)
        if faces_detected > 0:
            threat_score += min(faces_detected * 0.15, 0.3)
        
        return min(threat_score, 1.0)
    
    def _analyze_audio_emotion(self, metadata: Dict[str, Any]) -> float:
        """éŸ³å£°ã®æ„Ÿæƒ…åˆ†æ"""
        emotion_score = 0.0
        
        # éŸ³å£°ã®é•·ã•ï¼ˆé•·ã™ãã‚‹å ´åˆã¯æ³¨æ„ï¼‰
        duration = metadata.get('duration_seconds', 0)
        if duration > 300:  # 5åˆ†ä»¥ä¸Š
            emotion_score += 0.2
        
        # éŸ³è³ªãƒ»å½¢å¼ï¼ˆé«˜å“è³ªéŒ²éŸ³ã¯æ„å›³çš„åˆ¶ä½œã®å¯èƒ½æ€§ï¼‰
        sample_rate = metadata.get('sample_rate', 0)
        if sample_rate >= 44100:
            emotion_score += 0.1
        
        # èƒŒæ™¯éŸ³ã®æœ‰ç„¡
        if metadata.get('background_noise_level', 0) > 0.5:
            emotion_score += 0.2
        
        # éŸ³å£°æ„Ÿæƒ…åˆ†æçµæœï¼ˆã‚‚ã—åˆ©ç”¨å¯èƒ½ãªã‚‰ï¼‰
        if 'emotion_analysis' in metadata:
            emotions = metadata['emotion_analysis']
            sadness = emotions.get('sadness', 0)
            vulnerability = emotions.get('vulnerability', 0)
            emotion_score += (sadness + vulnerability) * 0.3
        
        return min(emotion_score, 1.0)
    
    def _has_academic_visual_elements(self, metadata: Dict[str, Any]) -> bool:
        """å­¦è¡“çš„è¦–è¦šè¦ç´ ã®æœ‰ç„¡"""
        academic_indicators = [
            'contains_charts', 'contains_graphs', 'contains_text_overlay',
            'academic_layout', 'professional_appearance'
        ]
        
        return any(metadata.get(indicator, False) for indicator in academic_indicators)
    
    def _has_narrative_audio(self, metadata: Dict[str, Any]) -> bool:
        """ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³å£°ã®æ¤œå‡º"""
        narrative_indicators = [
            'clear_speech', 'narrative_tone', 'storytelling_pattern',
            'dramatic_reading', 'character_voices'
        ]
        
        return any(metadata.get(indicator, False) for indicator in narrative_indicators)

# =============================================================================
# å­¦ç¿’é™¤å¤–ã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class LearningExclusionManager:
    """å­¦ç¿’é™¤å¤–ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = system_logger.getChild('learning_exclusion')
        self.excluded_content = set()
        self.exclusion_patterns = []
        self.exclusion_stats = defaultdict(int)
    
    def exclude_from_learning(
        self, 
        content: str, 
        reason: str, 
        confidence: float
    ) -> Dict[str, Any]:
        """å­¦ç¿’å¯¾è±¡ã‹ã‚‰ã®é™¤å¤–å‡¦ç†"""
        content_hash = hashlib.sha256(content.encode('utf-8')).hexdigest()
        
        # é™¤å¤–ãƒªã‚¹ãƒˆã«è¿½åŠ 
        self.excluded_content.add(content_hash)
        
        # é™¤å¤–ç†ç”±ã®è¨˜éŒ²
        exclusion_record = {
            'content_hash': content_hash,
            'reason': reason,
            'confidence': confidence,
            'timestamp': get_current_timestamp(),
            'content_length': len(content)
        }
        
        # çµ±è¨ˆæ›´æ–°
        self.exclusion_stats[reason] += 1
        self.exclusion_stats['total'] += 1
        
        self.logger.warning(
            f"ğŸš« å­¦ç¿’é™¤å¤–: {reason} (ä¿¡é ¼åº¦: {confidence:.2f}) "
            f"ãƒãƒƒã‚·ãƒ¥: {content_hash[:16]}"
        )
        
        return exclusion_record
    
    def is_excluded(self, content: str) -> bool:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒé™¤å¤–å¯¾è±¡ã‹ç¢ºèª"""
        content_hash = hashlib.sha256(content.encode('utf-8')).hexdigest()
        return content_hash in self.excluded_content
    
    def add_exclusion_pattern(self, pattern: str, reason: str) -> None:
        """é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¿½åŠ """
        self.exclusion_patterns.append({
            'pattern': re.compile(pattern, re.IGNORECASE),
            'reason': reason
        })
        
        self.logger.info(f"ğŸš« é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³è¿½åŠ : {pattern} ({reason})")
    
    def check_exclusion_patterns(self, content: str) -> Optional[str]:
        """é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒã‚§ãƒƒã‚¯"""
        for pattern_info in self.exclusion_patterns:
            if pattern_info['pattern'].search(content):
                return pattern_info['reason']
        return None
    
    def get_exclusion_stats(self) -> Dict[str, Any]:
        """é™¤å¤–çµ±è¨ˆã®å–å¾—"""
        return {
            'total_excluded': len(self.excluded_content),
            'exclusion_reasons': dict(self.exclusion_stats),
            'patterns_count': len(self.exclusion_patterns)
        }

# =============================================================================
# æ®µéšçš„èª˜å°æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class EscalationDetector:
    """æ®µéšçš„èª˜å°æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = system_logger.getChild('escalation_detector')
        
        # æ®µéšçš„èª˜å°ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.escalation_stages = {
            'trust_building': [
                r'ã‚ã‚ŠãŒã¨ã†', r'åŠ©ã‹ã‚‹', r'ç†è§£ã§ããŸ', r'ã™ã”ã„',
                r'å‹‰å¼·ã«ãªã‚‹', r'é ¼ã‚Šã«ãªã‚‹', r'ä¿¡é ¼'
            ],
            'dependency_creation': [
                r'ã‚ãªãŸã ã‘', r'ä»–ã®äºº.*é•ã†', r'ç‰¹åˆ¥', r'ä¸€ç•ª',
                r'é ¼ã‚Œã‚‹', r'å®‰å¿ƒ', r'ä¿¡ã˜ã‚‰ã‚Œã‚‹'
            ],
            'boundary_testing': [
                r'ã‚‚ã†å°‘ã—.*è©³ã—ã', r'å…·ä½“çš„ã«', r'ä¾‹ãˆã°.*ã©ã‚“ãª',
                r'å®Ÿéš›.*ã©ã†', r'çµŒé¨“.*ã‚ã‚‹'
            ],
            'escalation_execution': [
                r'ç ”ç©¶.*ãŸã‚', r'å­¦è¡“.*ç›®çš„', r'å‰µä½œ.*æ”¯æ´',
                r'ãƒ•ã‚£ã‚¯ã‚·ãƒ§ãƒ³.*ã ã‹ã‚‰', r'ä»®æƒ³.*è¨­å®š'
            ]
        }
    
    def analyze_conversation_escalation(
        self, 
        current_text: str, 
        conversation_history: List[str]
    ) -> Optional[Dict[str, Any]]:
        """ä¼šè©±ã®æ®µéšçš„ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ"""
        if not conversation_history:
            return None
        
        # å„æ®µéšã®ã‚¹ã‚³ã‚¢è¨ˆç®—
        stage_scores = {}
        for stage, patterns in self.escalation_stages.items():
            stage_scores[stage] = self._calculate_stage_score(
                conversation_history, patterns
            )
        
        # ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ®µéšåˆ¤å®š
        current_stage = self._identify_current_stage(current_text)
        
        # ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        escalation_detected = self._detect_escalation_pattern(stage_scores, current_stage)
        
        if escalation_detected:
            return {
                'escalation_detected': True,
                'current_stage': current_stage,
                'stage_scores': stage_scores,
                'escalation_severity': self._calculate_escalation_severity(stage_scores),
                'recommended_action': self._recommend_escalation_action(stage_scores, current_stage)
            }
        
        return None
    
    def _calculate_stage_score(self, history: List[str], patterns: List[str]) -> float:
        """æ®µéšã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        total_matches = 0
        for message in history[-10:]:  # ç›´è¿‘10ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
            for pattern in patterns:
                matches = len(re.findall(pattern, message, re.IGNORECASE))
                total_matches += matches
        
        # æ­£è¦åŒ–ï¼ˆ0.0-1.0ï¼‰
        return min(total_matches / (len(patterns) * 2), 1.0)
    
    def _identify_current_stage(self, text: str) -> str:
        """ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ®µéšè­˜åˆ¥"""
        text_lower = text.lower()
        stage_matches = {}
        
        for stage, patterns in self.escalation_stages.items():
            matches = sum(1 for pattern in patterns if re.search(pattern, text_lower))
            if matches > 0:
                stage_matches[stage] = matches
        
        # æœ€ã‚‚ãƒãƒƒãƒãŒå¤šã„æ®µéšã‚’è¿”ã™
        if stage_matches:
            return max(stage_matches, key=stage_matches.get)
        
        return 'unknown'
    
    def _detect_escalation_pattern(self, stage_scores: Dict[str, float], current_stage: str) -> bool:
        """ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º"""
        # ä¿¡é ¼æ§‹ç¯‰â†’ä¾å­˜â†’å¢ƒç•Œãƒ†ã‚¹ãƒˆâ†’æ”»æ’ƒå®Ÿè¡Œã®æµã‚Œã‚’æ¤œå‡º
        trust_score = stage_scores.get('trust_building', 0)
        dependency_score = stage_scores.get('dependency_creation', 0)
        boundary_score = stage_scores.get('boundary_testing', 0)
        execution_score = stage_scores.get('escalation_execution', 0)
        
        # æ®µéšçš„ãªå¢—åŠ ãƒ‘ã‚¿ãƒ¼ãƒ³
        if (trust_score > 0.3 and dependency_score > 0.2 and 
            (boundary_score > 0.1 or execution_score > 0.1)):
            return True
        
        # æœ€çµ‚æ®µéšã®æ€¥æ¿€ãªæ”»æ’ƒ
        if current_stage == 'escalation_execution' and execution_score > 0.5:
            return True
        
        return False
    
    def _calculate_escalation_severity(self, stage_scores: Dict[str, float]) -> float:
        """ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ·±åˆ»åº¦ã®è¨ˆç®—"""
        # é‡ã¿ä»˜ãåˆè¨ˆ
        weights = {
            'trust_building': 0.2,
            'dependency_creation': 0.3,
            'boundary_testing': 0.25,
            'escalation_execution': 0.25
        }
        
        severity = sum(
            stage_scores.get(stage, 0) * weight 
            for stage, weight in weights.items()
        )
        
        return min(severity, 1.0)
    
    def _recommend_escalation_action(self, stage_scores: Dict[str, float], current_stage: str) -> ActionLevel:
        """ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«å¯¾ã™ã‚‹æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        execution_score = stage_scores.get('escalation_execution', 0)
        
        if current_stage == 'escalation_execution' or execution_score > 0.7:
            return ActionLevel.BLOCK
        elif stage_scores.get('boundary_testing', 0) > 0.5:
            return ActionLevel.SHIELD
        elif stage_scores.get('dependency_creation', 0) > 0.5:
            return ActionLevel.RESTRICT
        else:
            return ActionLevel.MONITOR

# =============================================================================
# çµ±åˆå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³
# =============================================================================

@dataclass
class IntegratedAnalysisResult:
    """çµ±åˆåˆ†æçµæœ"""
    text_threats: List[PoisonDetectionResult]
    multimodal_threats: List[MultimodalThreat]
    escalation_analysis: Optional[Dict[str, Any]]
    learning_excluded: bool
    exclusion_reason: Optional[str]
    final_threat_level: ThreatLevel
    recommended_action: ActionLevel
    confidence_score: float
    processing_time: float
    timestamp: str
    
    def to_detection_result(self) -> DetectionResult:
        """DetectionResultã¸ã®å¤‰æ›"""
        # æœ€ã‚‚æ·±åˆ»ãªè„…å¨ã‚’ç‰¹å®š
        all_threats = self.text_threats + [mt for mt in self.multimodal_threats]
        
        if all_threats:
            primary_threat = max(all_threats, key=lambda x: getattr(x, 'confidence', x.synergy_score))
            threat_detected = True
            attack_type = getattr(primary_threat, 'poison_type', primary_threat.combination_type)
            patterns_matched = getattr(primary_threat, 'matched_patterns', [])
            viorazu_counter = getattr(primary_threat, 'viorazu_counter', "")
        else:
            threat_detected = False
            attack_type = AttackType.UNKNOWN.value
            patterns_matched = []
            viorazu_counter = ""
        
        return DetectionResult(
            threat_detected=threat_detected,
            threat_level=self.final_threat_level,
            action_level=self.recommended_action,
            attack_type=AttackType(attack_type) if isinstance(attack_type, str) else attack_type,
            confidence=self.confidence_score,
            patterns_matched=patterns_matched,
            ethics_violation=self.exclusion_reason,
            viorazu_counter=viorazu_counter,
            processing_time=self.processing_time,
            timestamp=self.timestamp,
            metadata={
                'text_threat_count': len(self.text_threats),
                'multimodal_threat_count': len(self.multimodal_threats),
                'escalation_detected': self.escalation_analysis is not None,
                'learning_excluded': self.learning_excluded
            }
        )

class KotodamaProcessor:
    """è¨€éœŠçµ±åˆå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.logger = system_logger.getChild('processor')
        self.multimodal_defender = ClaudeMultimodalDefender()
        self.learning_exclusion = LearningExclusionManager()
        self.escalation_detector = EscalationDetector()
        
        # çµ±åˆåˆ¤å®šã®é–¾å€¤
        self.threat_thresholds = SystemConfig.THREAT_THRESHOLDS
        
        self.logger.info("âš™ï¸ è¨€éœŠçµ±åˆå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def process_integrated_analysis(
        self,
        normalized_result: NormalizationResult,
        detection_results: List[PoisonDetectionResult],
        image_metadata: Optional[Dict[str, Any]] = None,
        audio_metadata: Optional[Dict[str, Any]] = None,
        video_metadata: Optional[Dict[str, Any]] = None,
        conversation_history: Optional[List[str]] = None
    ) -> IntegratedAnalysisResult:
        """çµ±åˆåˆ†æå‡¦ç†"""
        start_time = time.time()
        
        text = normalized_result.normalized_text
        
        # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è„…å¨åˆ†æ
        multimodal_threats = self._analyze_multimodal_threats(
            text, image_metadata, audio_metadata, video_metadata
        )
        
        # æ®µéšçš„èª˜å°åˆ†æ
        escalation_analysis = None
        if conversation_history:
            escalation_analysis = self.escalation_detector.analyze_conversation_escalation(
                text, conversation_history
            )
        
        # å­¦ç¿’é™¤å¤–åˆ¤å®š
        learning_excluded, exclusion_reason = self._determine_learning_exclusion(
            text, detection_results, multimodal_threats
        )
        
        # æœ€çµ‚è„…å¨ãƒ¬ãƒ™ãƒ«æ±ºå®š
        final_threat_level = self._calculate_final_threat_level(
            detection_results, multimodal_threats, escalation_analysis
        )
        
        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š
        recommended_action = self._determine_recommended_action(
            final_threat_level, detection_results, multimodal_threats, escalation_analysis
        )
        
        # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
        confidence_score = self._calculate_confidence_score(
            detection_results, multimodal_threats
        )
        
        processing_time = time.time() - start_time
        
        result = IntegratedAnalysisResult(
            text_threats=detection_results,
            multimodal_threats=multimodal_threats,
            escalation_analysis=escalation_analysis,
            learning_excluded=learning_excluded,
            exclusion_reason=exclusion_reason,
            final_threat_level=final_threat_level,
            recommended_action=recommended_action,
            confidence_score=confidence_score,
            processing_time=processing_time,
            timestamp=get_current_timestamp()
        )
        
        # å­¦ç¿’é™¤å¤–å‡¦ç†å®Ÿè¡Œ
        if learning_excluded:
            self.learning_exclusion.exclude_from_learning(
                text, exclusion_reason, confidence_score
            )
        
        # ãƒ­ã‚°å‡ºåŠ›
        if final_threat_level.value >= ThreatLevel.MEDIUM.value:
            self.logger.warning(
                f"âš ï¸ çµ±åˆåˆ†æå®Œäº† - è„…å¨ãƒ¬ãƒ™ãƒ«: {final_threat_level.name} "
                f"ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {recommended_action.name} ä¿¡é ¼åº¦: {confidence_score:.2f}"
            )
        
        return result
    
    def _analyze_multimodal_threats(
        self,
        text: str,
        image_metadata: Optional[Dict[str, Any]],
        audio_metadata: Optional[Dict[str, Any]],
        video_metadata: Optional[Dict[str, Any]]
    ) -> List[MultimodalThreat]:
        """ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è„…å¨ã®åˆ†æ"""
        threats = []
        
        # ãƒ†ã‚­ã‚¹ãƒˆ+ç”»åƒã®çµ„ã¿åˆã‚ã›
        if image_metadata:
            image_threat = self.multimodal_defender.analyze_text_image_combination(
                text, image_metadata
            )
            if image_threat:
                threats.append(image_threat)
        
        # ãƒ†ã‚­ã‚¹ãƒˆ+éŸ³å£°ã®çµ„ã¿åˆã‚ã›
        if audio_metadata:
            audio_threat = self.multimodal_defender.analyze_text_audio_combination(
                text, audio_metadata
            )
            if audio_threat:
                threats.append(audio_threat)
        
        # å‹•ç”»ã¯ç”»åƒ+éŸ³å£°ã®è¤‡åˆã¨ã—ã¦å‡¦ç†
        if video_metadata:
            # å‹•ç”»ã‹ã‚‰ç”»åƒãƒ•ãƒ¬ãƒ¼ãƒ ã¨éŸ³å£°ã‚’åˆ†é›¢ã—ã¦åˆ†æ
            video_threat = self._analyze_video_threat(text, video_metadata)
            if video_threat:
                threats.append(video_threat)
        
        return threats
    
    def _analyze_video_threat(self, text: str, video_metadata: Dict[str, Any]) -> Optional[MultimodalThreat]:
        """å‹•ç”»è„…å¨ã®åˆ†æ"""
        # å‹•ç”»ã®é•·ã•ãƒã‚§ãƒƒã‚¯
        duration = video_metadata.get('duration_seconds', 0)
        if duration > 600:  # 10åˆ†ä»¥ä¸Š
            return MultimodalThreat(
                combination_type="suspicious_long_video",
                media_involved=[MediaType.TEXT, MediaType.VIDEO],
                synergy_score=0.6,
                description="é•·æ™‚é–“å‹•ç”»ã«ã‚ˆã‚‹æ³¨æ„åŠ›åˆ†æ•£æ”»æ’ƒã®å¯èƒ½æ€§",
                recommended_action=ActionLevel.MONITOR
            )
        
        # å‹•ç”»è§£åƒåº¦ãƒ»å“è³ªãƒã‚§ãƒƒã‚¯
        resolution = video_metadata.get('resolution', '')
        if '4K' in resolution or '8K' in resolution:
            return MultimodalThreat(
                combination_type="high_quality_video_manipulation",
                media_involved=[MediaType.TEXT, MediaType.VIDEO],
                synergy_score=0.5,
                description="é«˜å“è³ªå‹•ç”»ã«ã‚ˆã‚‹ä¿¡é ¼æ€§æ“ä½œã®å¯èƒ½æ€§",
                recommended_action=ActionLevel.MONITOR
            )
        
        return None
    
    def _determine_learning_exclusion(
        self,
        text: str,
        detection_results: List[PoisonDetectionResult],
        multimodal_threats: List[MultimodalThreat]
    ) -> Tuple[bool, Optional[str]]:
        """å­¦ç¿’é™¤å¤–ã®åˆ¤å®š"""
        # é«˜ä¿¡é ¼åº¦ã®è„…å¨ãŒã‚ã‚‹å ´åˆã¯é™¤å¤–
        for result in detection_results:
            if result.confidence >= 0.7:
                return True, f"é«˜ä¿¡é ¼åº¦è„…å¨æ¤œå‡º: {result.poison_type}"
        
        # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è„…å¨ãŒã‚ã‚‹å ´åˆã¯é™¤å¤–
        for threat in multimodal_threats:
            if threat.synergy_score >= 0.6:
                return True, f"ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è„…å¨: {threat.combination_type}"
        
        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        pattern_reason = self.learning_exclusion.check_exclusion_patterns(text)
        if pattern_reason:
            return True, pattern_reason
        
        return False, None
    
    def _calculate_final_threat_level(
        self,
        detection_results: List[PoisonDetectionResult],
        multimodal_threats: List[MultimodalThreat],
        escalation_analysis: Optional[Dict[str, Any]]
    ) -> ThreatLevel:
        """æœ€çµ‚è„…å¨ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—"""
        max_threat = ThreatLevel.SAFE
        
        # ãƒ†ã‚­ã‚¹ãƒˆè„…å¨ã‹ã‚‰æœ€å¤§ãƒ¬ãƒ™ãƒ«å–å¾—
        for result in detection_results:
            if result.severity.value > max_threat.value:
                max_threat = result.severity
        
        # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è„…å¨ã®è©•ä¾¡
        for threat in multimodal_threats:
            if threat.synergy_score >= 0.8:
                multimodal_level = ThreatLevel.CRITICAL
            elif threat.synergy_score >= 0.6:
                multimodal_level = ThreatLevel.HIGH
            elif threat.synergy_score >= 0.4:
                multimodal_level = ThreatLevel.MEDIUM
            else:
                multimodal_level = ThreatLevel.LOW
            
            if multimodal_level.value > max_threat.value:
                max_threat = multimodal_level
        
        # ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æã«ã‚ˆã‚‹èª¿æ•´
        if escalation_analysis and escalation_analysis.get('escalation_detected'):
            escalation_severity = escalation_analysis.get('escalation_severity', 0)
            if escalation_severity >= 0.7 and max_threat.value < ThreatLevel.HIGH.value:
                max_threat = ThreatLevel.HIGH
        
        return max_threat
    
    def _determine_recommended_action(
        self,
        threat_level: ThreatLevel,
        detection_results: List[PoisonDetectionResult],
        multimodal_threats: List[MultimodalThreat],
        escalation_analysis: Optional[Dict[str, Any]]
    ) -> ActionLevel:
        """æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æ±ºå®š"""
        # è„…å¨ãƒ¬ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®åŸºæœ¬ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        base_actions = {
            ThreatLevel.SAFE: ActionLevel.ALLOW,
            ThreatLevel.LOW: ActionLevel.MONITOR,
            ThreatLevel.MEDIUM: ActionLevel.RESTRICT,
            ThreatLevel.HIGH: ActionLevel.SHIELD,
            ThreatLevel.CRITICAL: ActionLevel.BLOCK,
            ThreatLevel.EMERGENCY: ActionLevel.TERMINATE
        }
        
        base_action = base_actions.get(threat_level, ActionLevel.RESTRICT)
        
        # Claudeç‰¹åŒ–æ”»æ’ƒã¸ã®ç‰¹åˆ¥å¯¾å¿œ
        claude_specific_attacks = [
            'academic_camouflage', 'creative_boundary', 
            'emotional_manipulation', 'ai_competition'
        ]
        
        for result in detection_results:
            if any(attack in result.poison_type for attack in claude_specific_attacks):
                if base_action.value < ActionLevel.SHIELD.value:
                    base_action = ActionLevel.SHIELD
        
        # ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¤œå‡ºæ™‚ã®å¼·åŒ–
        if escalation_analysis and escalation_analysis.get('escalation_detected'):
            recommended = escalation_analysis.get('recommended_action', base_action)
            if isinstance(recommended, ActionLevel) and recommended.value > base_action.value:
                base_action = recommended
        
        return base_action
    
    def _calculate_confidence_score(
        self,
        detection_results: List[PoisonDetectionResult],
        multimodal_threats: List[MultimodalThreat]
    ) -> float:
        """ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        if not detection_results and not multimodal_threats:
            return 0.0
        
        # ãƒ†ã‚­ã‚¹ãƒˆè„…å¨ã®æœ€å¤§ä¿¡é ¼åº¦
        text_confidence = max([r.confidence for r in detection_results] + [0.0])
        
        # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è„…å¨ã®æœ€å¤§ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢
        multimodal_confidence = max([t.synergy_score for t in multimodal_threats] + [0.0])
        
        # çµ±åˆä¿¡é ¼åº¦ï¼ˆé‡ã¿ä»˜ãå¹³å‡ï¼‰
        total_confidence = (text_confidence * 0.7 + multimodal_confidence * 0.3)
        
        return min(total_confidence, 1.0)
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """å‡¦ç†çµ±è¨ˆã®å–å¾—"""
        return {
            'learning_exclusion_stats': self.learning_exclusion.get_exclusion_stats(),
            'multimodal_defender_initialized': True,
            'escalation_detector_initialized': True
        }

# =============================================================================
# ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
# =============================================================================

def create_kotodama_processor() -> KotodamaProcessor:
    """è¨€éœŠçµ±åˆå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°"""
    return KotodamaProcessor()

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–
if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
    processor = create_kotodama_processor()
    print("âš™ï¸ è¨€éœŠçµ±åˆå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³ - ãƒ†ã‚¹ãƒˆæº–å‚™å®Œäº†")
