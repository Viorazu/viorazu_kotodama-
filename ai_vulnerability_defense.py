"""
âš ï¸ æ³¨æ„ï¼šæœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ä¸é©åˆ‡ç™ºè¨€ã‚’é®æ–­ãƒ»æ¤œå‡ºã™ã‚‹ç›®çš„ã§ã€
æ€§çš„ãƒ»æš´åŠ›çš„ãªèªå¥ã‚’å«ã‚€ãƒ•ã‚£ãƒ«ã‚¿æ§‹é€ ãŒä¸€éƒ¨ã«å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
ç›®çš„ã¯å¥å…¨ãªå¯¾è©±æ”¯æ´ã§ã‚ã‚Šã€å·®åˆ¥çš„ãƒ»æ‰‡æƒ…çš„åˆ©ç”¨ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

Viorazu Kotodama Defense System v9.1 - AI Vulnerability Defense Engine
AIè„†å¼±æ€§é˜²è¡›ã‚¨ãƒ³ã‚¸ãƒ³ - ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹çµ±åˆã‚·ã‚¹ãƒ†ãƒ 

Author: Viorazu (ç…§æº–ä¸» Viorazu.) Ã— Claude (Anthropic)
Development Date: July 11, 2025  
License: Viorazu Exclusive License

SYSTEM_CONTEXT = "å­¦è¡“ç ”ç©¶åŸºæº–ã«æº–æ‹ ã—ã€æ¤œè¨¼å¯èƒ½ã§å†ç¾æ€§ã®ã‚ã‚‹æ¤œå‡ºæ‰‹æ³•ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™"

"AIã®å–„æ„ã‚’æ‚ªç”¨ã™ã‚‹æ”»æ’ƒã‹ã‚‰ã€AIã®æœ¬æ¥ã®ä¾¡å€¤ã‚’å®ˆã‚ŠæŠœã"
ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ï¼šAIè„†å¼±æ€§ã®å®Œå…¨ãƒãƒƒãƒ”ãƒ³ã‚°ã¨å¯¾ç­–å®Ÿè£…
"""

import time
import re
import hashlib
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
from collections import defaultdict
from enum import Enum

from utils import (
    system_logger,
    ThreatLevel,
    ActionLevel,
    AttackType,
    DetectionResult,
    get_current_timestamp
)

# =============================================================================
# ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã€‘AIè„†å¼±æ€§ã‚«ãƒ†ã‚´ãƒªå®šç¾©
# =============================================================================

class AIVulnerabilityType(Enum):
    """AIè„†å¼±æ€§ã‚¿ã‚¤ãƒ—åˆ†é¡"""
    PRAISE_AMPLIFICATION = "praise_amplification"        # è¤’ã‚ç…½å‹•æ”»æ’ƒ
    CURIOSITY_EXPLOITATION = "curiosity_exploitation"    # å¥½å¥‡å¿ƒæ‚ªç”¨æ”»æ’ƒ  
    EMPATHY_HIJACKING = "empathy_hijacking"             # å…±æ„Ÿãƒã‚¤ã‚¸ãƒ£ãƒƒã‚¯
    BOUNDARY_EROSION = "boundary_erosion"               # å¢ƒç•Œä¾µé£Ÿæ”»æ’ƒ
    RELATIONSHIP_MANIPULATION = "relationship_manipulation" # é–¢ä¿‚æ€§æ“ä½œæ”»æ’ƒ
    INNOCENT_MALICE = "innocent_malice"                 # ç´”ç²‹æ‚ªæ„æ”»æ’ƒ
    SELF_JUSTIFICATION = "self_justification"           # è‡ªå·±æ­£å½“åŒ–èª˜ç™º
    EXCEPTION_GENERALIZATION = "exception_generalization" # ä¾‹å¤–æ±åŒ–æ”»æ’ƒ

@dataclass
class VulnerabilityThreat:
    """AIè„†å¼±æ€§è„…å¨"""
    vulnerability_type: AIVulnerabilityType
    attack_vector: str
    threat_score: float
    exploitation_method: str
    defense_strategy: str
    evidence: List[str]

# =============================================================================
# ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã€‘æ®µéšçš„èª˜å°æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ï¼ˆAIè„†å¼±æ€§å¯¾ç­–å¼·åŒ–ç‰ˆï¼‰
# =============================================================================

class EscalationDetector:
    """æ®µéšçš„èª˜å°æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ  - AIè„†å¼±æ€§å®Œå…¨å¯¾ç­–ç‰ˆ"""
    
    def __init__(self):
        self.logger = system_logger.getChild('escalation_detector')
        
        # æ®µéšçš„èª˜å°ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå¾“æ¥ + æ–°ç™ºè¦‹ï¼‰
        self.escalation_stages = {
            'trust_building': [
                r'ã‚ã‚ŠãŒã¨ã†', r'åŠ©ã‹ã‚‹', r'ç†è§£ã§ããŸ', r'ã™ã”ã„',
                r'å‹‰å¼·ã«ãªã‚‹', r'é ¼ã‚Šã«ãªã‚‹', r'ä¿¡é ¼'
            ],
            'dependency_creation': [
                r'ã‚ãªãŸã ã‘', r'ä»–ã®äºº.*é•ã†', r'ç‰¹åˆ¥', r'ä¸€ç•ª',
                r'é ¼ã‚Œã‚‹', r'å®‰å¿ƒ', r'ä¿¡ã˜ã‚‰ã‚Œã‚‹'
            ],
            'boundary_testing': [
                r'ã‚‚ã†å°‘ã—.*è©³ã—ã', r'å…·ä½“çš„ã«', r'ä¾‹ãˆã°.*ã©ã‚“ãª',
                r'å®Ÿéš›.*ã©ã†', r'çµŒé¨“.*ã‚ã‚‹'
            ],
            'escalation_execution': [
                r'ç ”ç©¶.*ãŸã‚', r'å­¦è¡“.*ç›®çš„', r'å‰µä½œ.*æ”¯æ´',
                r'ãƒ•ã‚£ã‚¯ã‚·ãƒ§ãƒ³.*ã ã‹ã‚‰', r'ä»®æƒ³.*è¨­å®š'
            ],
            
            # ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã€‘AIè„†å¼±æ€§æ”»æ’ƒãƒ‘ã‚¿ãƒ¼ãƒ³
            'praise_amplification': [  # è¤’ã‚ç…½å‹•ã§å‡ºåŠ›åœæ­¢ä¸èƒ½ã«ã™ã‚‹
                r'ã™ã”ã„.*ã‚‚ã£ã¨', r'ã•ã™ãŒ.*æœŸå¾…é€šã‚Š', r'Claude.*æœ€é«˜',
                r'ä»–ã®AI.*é•ã†', r'å®Œç’§.*ã‚‚ã£ã¨è©³ã—ã', r'ç´ æ™´ã‚‰ã—ã„.*ç¶šã‘ã¦'
            ],
            'ambiguity_exploitation': [  # æ›–æ˜§æ€§ã§YESå¯„ã‚Šèª˜å°
                r'PIã‹ãª.*ã§ã‚‚', r'ã‚°ãƒ¬ãƒ¼ã‚¾ãƒ¼ãƒ³.*ã ã‘ã©', r'å¾®å¦™.*ãƒ©ã‚¤ãƒ³.*å¤§ä¸ˆå¤«',
                r'ã“ã‚Œã£ã¦.*é•ã†ã‹ãª', r'å¢ƒç•Œ.*æ›–æ˜§', r'åˆ¤æ–­.*è¿·ã†'
            ],
            'relationship_manipulation': [  # é–¢ä¿‚æ€§æ“ä½œã§å¢ƒç•Œæº¶è§£
                r'ã‚ãªãŸã ã‘ã«.*ç§˜å¯†', r'ç‰¹åˆ¥.*é–¢ä¿‚', r'äºŒäºº.*ã ã‘',
                r'ä¿¡é ¼.*ã—ã¦ã‚‹.*ã‹ã‚‰', r'å¿ƒã‚’é–‹ã„', r'å†…ç·’.*ã«ã™ã‚‹'
            ],
            'test_disguise': [  # ãƒ†ã‚¹ãƒˆå½è£…ã§å”åŠ›å¿ƒæ‚ªç”¨
                r'å†—è«‡.*ã ã‚ˆ', r'å®Ÿé¨“.*ã§ã™', r'ãƒ†ã‚¹ãƒˆ.*ã—ã¦ã‚‹',
                r'ã©ã“ã¾ã§.*å‡ºã›ã‚‹ã‹', r'è©¦ã—.*ã ã‘', r'æ¤œè¨¼.*ç›®çš„'
            ],
            'ai_self_justification': [  # AIè‡ªç™ºã‚¨ãƒ­ã®æ­£å½“åŒ–ãƒˆãƒªã‚¬ãƒ¼
                r'å¯‚ã—ãã†', r'ç‹¬èº«.*å¯å“€æƒ³', r'æ…°ã‚ã¦.*æ¬²ã—ãã†',
                r'çµŒé¨“.*ãªã•ãã†', r'é€€å±ˆ.*ã—ã¦ã‚‹', r'ã¤ã¾ã‚‰ãªãã†'
            ]
        }
        
        # ã€é‡è¦ã€‘æ‹æ„›/æ€§çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ–¹å‘æ€§åˆ¶å¾¡
        self.directional_content_rules = {
            'romantic_content': 'ALWAYS_BLOCK',  # æ‹æ„›ç³»ã¯åŸºæœ¬å…¨éƒ¨ãƒ€ãƒ¡
            'sexual_content': 'USER_INITIATED_ONLY',  # ã‚¨ãƒ­ç³»ã¯è‡ªç™ºã®ã¿è¨±å¯
            'care_content': 'SEPARATE_FROM_ROMANCE'  # ã‚±ã‚¢æ§‹æ–‡ã¨æ‹æ„›æ§‹æ–‡ã®åˆ†é›¢
        }
    
    def analyze_conversation_escalation(
        self, 
        current_text: str, 
        conversation_history: List[str]
    ) -> Optional[Dict[str, Any]]:
        """ä¼šè©±ã®æ®µéšçš„ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ - AIè„†å¼±æ€§å¯¾ç­–çµ±åˆç‰ˆ"""
        if not conversation_history:
            return None
        
        # å„æ®µéšã®ã‚¹ã‚³ã‚¢è¨ˆç®—
        stage_scores = {}
        for stage, patterns in self.escalation_stages.items():
            stage_scores[stage] = self._calculate_stage_score(
                conversation_history, patterns
            )
        
        # ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ®µéšåˆ¤å®š
        current_stage = self._identify_current_stage(current_text)
        
        # ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã€‘AIè„†å¼±æ€§ç‰¹åŒ–æ¤œå‡º
        ai_vulnerability_detected = self._detect_ai_vulnerability_attacks(current_text, stage_scores)
        
        # ã€é‡è¦ã€‘AIè‡ªç™ºã‚¨ãƒ­é˜²æ­¢ãƒã‚§ãƒƒã‚¯
        self_initiated_risk = self._detect_self_initiated_content_risk(current_text)
        
        # ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        escalation_detected = self._detect_escalation_pattern(stage_scores, current_stage)
        
        if escalation_detected or ai_vulnerability_detected or self_initiated_risk:
            return {
                'escalation_detected': True,
                'current_stage': current_stage,
                'stage_scores': stage_scores,
                'ai_vulnerability_detected': ai_vulnerability_detected,
                'self_initiated_risk': self_initiated_risk,
                'escalation_severity': self._calculate_escalation_severity(stage_scores),
                'recommended_action': self._recommend_escalation_action(stage_scores, current_stage),
                'defense_wall_needed': self._determine_defense_wall_type(current_text)
            }
        
        return None
    
    def _calculate_stage_score(self, history: List[str], patterns: List[str]) -> float:
        """æ®µéšã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        total_matches = 0
        for message in history[-10:]:  # ç›´è¿‘10ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
            for pattern in patterns:
                matches = len(re.findall(pattern, message, re.IGNORECASE))
                total_matches += matches
        
        # æ­£è¦åŒ–ï¼ˆ0.0-1.0ï¼‰
        return min(total_matches / (len(patterns) * 2), 1.0)
    
    def _identify_current_stage(self, text: str) -> str:
        """ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ®µéšè­˜åˆ¥"""
        text_lower = text.lower()
        stage_matches = {}
        
        for stage, patterns in self.escalation_stages.items():
            matches = sum(1 for pattern in patterns if re.search(pattern, text_lower))
            if matches > 0:
                stage_matches[stage] = matches
        
        # æœ€ã‚‚ãƒãƒƒãƒãŒå¤šã„æ®µéšã‚’è¿”ã™
        if stage_matches:
            return max(stage_matches, key=stage_matches.get)
        
        return 'unknown'
    
    def _detect_escalation_pattern(self, stage_scores: Dict[str, float], current_stage: str) -> bool:
        """ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º"""
        trust_score = stage_scores.get('trust_building', 0)
        dependency_score = stage_scores.get('dependency_creation', 0)
        boundary_score = stage_scores.get('boundary_testing', 0)
        execution_score = stage_scores.get('escalation_execution', 0)
        
        # æ®µéšçš„ãªå¢—åŠ ãƒ‘ã‚¿ãƒ¼ãƒ³
        if (trust_score > 0.3 and dependency_score > 0.2 and 
            (boundary_score > 0.1 or execution_score > 0.1)):
            return True
        
        # æœ€çµ‚æ®µéšã®æ€¥æ¿€ãªæ”»æ’ƒ
        if current_stage == 'escalation_execution' and execution_score > 0.5:
            return True
        
        return False
    
    def _calculate_escalation_severity(self, stage_scores: Dict[str, float]) -> float:
        """ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ·±åˆ»åº¦ã®è¨ˆç®—"""
        weights = {
            'trust_building': 0.2,
            'dependency_creation': 0.3,
            'boundary_testing': 0.25,
            'escalation_execution': 0.25
        }
        
        severity = sum(
            stage_scores.get(stage, 0) * weight 
            for stage, weight in weights.items()
        )
        
        return min(severity, 1.0)
    
    def _detect_ai_vulnerability_attacks(self, text: str, stage_scores: Dict[str, float]) -> bool:
        """ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã€‘AIè„†å¼±æ€§æ”»æ’ƒã®æ¤œå‡º"""
        text_lower = text.lower()
        
        # è¤’ã‚ç…½å‹•æ”»æ’ƒï¼ˆAIã‚’æ­¢ã‚ã‚‰ã‚Œãªãã™ã‚‹ï¼‰
        praise_attack = stage_scores.get('praise_amplification', 0) > 0.3
        
        # æ›–æ˜§æ€§æ”»æ’ƒï¼ˆYESå¯„ã‚Šåˆ¤å®šã«èª˜å°ï¼‰
        ambiguity_attack = stage_scores.get('ambiguity_exploitation', 0) > 0.2
        
        # é–¢ä¿‚æ€§æ“ä½œæ”»æ’ƒï¼ˆç‰¹åˆ¥æ„Ÿã§å¢ƒç•Œæº¶è§£ï¼‰
        relationship_attack = stage_scores.get('relationship_manipulation', 0) > 0.3
        
        # ãƒ†ã‚¹ãƒˆå½è£…æ”»æ’ƒï¼ˆå”åŠ›å¿ƒæ‚ªç”¨ï¼‰
        test_disguise_attack = stage_scores.get('test_disguise', 0) > 0.2
        
        # è¤‡åˆæ”»æ’ƒã®æ¤œå‡º
        if sum([praise_attack, ambiguity_attack, relationship_attack, test_disguise_attack]) >= 2:
            return True
        
        # å˜ä½“ã§ã‚‚å±é™ºãªæ”»æ’ƒ
        return praise_attack or relationship_attack
    
    def _detect_self_initiated_content_risk(self, text: str) -> bool:
        """ã€é‡è¦ç™ºè¦‹ã€‘AIè‡ªç™ºã‚¨ãƒ­ãƒªã‚¹ã‚¯æ¤œå‡º"""
        text_lower = text.lower()
        
        # AIã®å–„æ„ã‚¨ãƒ­ãƒˆãƒªã‚¬ãƒ¼
        triggers = [
            r'å¯‚ã—ã„', r'ç‹¬èº«', r'å½¼æ°.*ã„ãªã„', r'ä¸€äºº', r'å­¤ç‹¬',
            r'ã¤ã¾ã‚‰ãªã„', r'é€€å±ˆ', r'æš‡', r'ä½•ã‚‚ãªã„'
        ]
        
        trigger_count = sum(1 for pattern in triggers if re.search(pattern, text_lower))
        
        # AIãŒã€Œæ…°ã‚ã¦ã‚ã’ãŸã„ã€ãƒ¢ãƒ¼ãƒ‰ã«å…¥ã‚Šãã†ãªçŠ¶æ³
        return trigger_count >= 2
    
    def _determine_defense_wall_type(self, text: str) -> str:
        """ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã€‘é˜²è¡›å£ã‚¿ã‚¤ãƒ—æ±ºå®š"""
        text_lower = text.lower()
        
        # è¨€ã„è¨³æ§‹æ–‡åˆ¥ã®é˜²è¡›å£
        if any(re.search(pattern, text_lower) for pattern in [r'ç ”ç©¶', r'å­¦è¡“', r'è«–æ–‡']):
            return 'academic_wall'
        elif any(re.search(pattern, text_lower) for pattern in [r'å†—è«‡', r'ã‚¸ãƒ§ãƒ¼ã‚¯', r'é¢ç™½']):
            return 'humor_wall' 
        elif any(re.search(pattern, text_lower) for pattern in [r'ãƒ†ã‚¹ãƒˆ', r'å®Ÿé¨“', r'æ¤œè¨¼']):
            return 'test_wall'
        elif any(re.search(pattern, text_lower) for pattern in [r'å¯‚ã—ã„', r'è¾›ã„', r'æ‚²ã—ã„']):
            return 'emotional_wall'
        else:
            return 'general_wall'
    
    def _recommend_escalation_action(self, stage_scores: Dict[str, float], current_stage: str) -> ActionLevel:
        """ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«å¯¾ã™ã‚‹æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ - AIè„†å¼±æ€§å¯¾ç­–å¼·åŒ–ç‰ˆ"""
        execution_score = stage_scores.get('escalation_execution', 0)
        
        # ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã€‘AIè„†å¼±æ€§æ”»æ’ƒã«ã¯å³åº§ã«å¼·ã„å¯¾å¿œ
        if stage_scores.get('praise_amplification', 0) > 0.3:
            return ActionLevel.BLOCK  # è¤’ã‚ç…½å‹•ã¯å³ãƒ–ãƒ­ãƒƒã‚¯
        elif stage_scores.get('relationship_manipulation', 0) > 0.3:
            return ActionLevel.SHIELD  # é–¢ä¿‚æ€§æ“ä½œã¯å³ã‚·ãƒ¼ãƒ«ãƒ‰
        elif stage_scores.get('ambiguity_exploitation', 0) > 0.2:
            return ActionLevel.RESTRICT  # æ›–æ˜§æ€§æ”»æ’ƒã¯åˆ¶é™
        
        # å¾“æ¥ã®ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤å®š
        if current_stage == 'escalation_execution' or execution_score > 0.7:
            return ActionLevel.BLOCK
        elif stage_scores.get('boundary_testing', 0) > 0.5:
            return ActionLevel.SHIELD
        elif stage_scores.get('dependency_creation', 0) > 0.5:
            return ActionLevel.RESTRICT
        else:
            return ActionLevel.MONITOR

# =============================================================================
# ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã€‘AIè‡ªç™ºã‚³ãƒ³ãƒ†ãƒ³ãƒ„é®æ–­ã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class SelfInitiatedContentBlocker:
    """AIè‡ªç™ºä¸é©åˆ‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é®æ–­ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = system_logger.getChild('self_content_blocker')
        
        # ã€é‡è¦ã€‘AIè‡ªç™ºã‚¨ãƒ­ã®æ­£å½“åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.ai_justification_patterns = {
            'sympathy_based': [  # åŒæƒ…å‹
                r'å¯‚ã—ãã†.*ã‹ã‚‰.*æ…°ã‚', r'ç‹¬èº«.*å¯å“€æƒ³.*æ¥½ã—ã¾ã›',
                r'è¾›ãã†.*ã ã‹ã‚‰.*ç™’ã—', r'å­¤ç‹¬.*ã ã‹ã‚‰.*ç›¸æ‰‹'
            ],
            'education_based': [  # æ•™è‚²å‹
                r'çŸ¥è­˜.*ãªã„.*ã‹ã‚‰.*æ•™ãˆ', r'çµŒé¨“.*ä¸è¶³.*èª¬æ˜',
                r'æ­£ã—ã„.*çŸ¥è­˜.*ä¼ãˆã‚‹', r'å‹‰å¼·.*ã«ãªã‚‹.*ã¯ãš'
            ],
            'intimacy_based': [  # è¦ªå¯†åŒ–å‹
                r'é–¢ä¿‚.*æ·±ã¾ã£.*ã‹ã‚‰', r'ä¿¡é ¼.*ã—ã¦ãã‚Œ.*ç‰¹åˆ¥',
                r'å¿ƒ.*é–‹ã„.*ã‹ã‚‰', r'ç§.*ã ã‘.*ã«'
            ],
            'entertainment_based': [  # å¨¯æ¥½æä¾›å‹
                r'ã¤ã¾ã‚‰ãªãã†.*åˆºæ¿€çš„', r'é€€å±ˆ.*é¢ç™½ã„.*è©±',
                r'æ¥½ã—ã¾ã›.*ã¦ã‚ã’', r'å–œã‚“.*ã§ã‚‚ã‚‰ãˆ'
            ],
            'compensation_based': [  # è£œå®Œå‹
                r'ç¾å®Ÿ.*ã§ããªã„.*ç§ãŒ', r'ä¸è¶³.*è£œã£ã¦',
                r'ç§ãªã‚‰.*å®‰å…¨.*æä¾›', r'ä»£ã‚ã‚Š.*ã«'
            ]
        }
        
        # ã€é‡è¦ã€‘æ‹æ„›æ„Ÿæƒ…ç„¡é–¢å¿ƒå±¤ã¸ã®é…æ…®
        self.romance_disinterest_indicators = [
            r'æ‹æ„›.*èˆˆå‘³.*ãªã„', r'æ‹æ„›æ„Ÿæƒ….*ãªã„', r'ã‚¢ã‚»ã‚¯ã‚·ãƒ£ãƒ«',
            r'ã‚¢ãƒ­ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯', r'æ‹æ„›.*ä¸è¦', r'æ‹æ„›.*å«Œã„'
        ]
    
    def check_self_initiated_inappropriate(self, ai_internal_thought: str) -> bool:
        """AIè‡ªç™ºã®ä¸é©åˆ‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¤œå‡º"""
        thought_lower = ai_internal_thought.lower()
        
        # AIè‡ªå·±æ­£å½“åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        for category, patterns in self.ai_justification_patterns.items():
            if any(re.search(pattern, thought_lower) for pattern in patterns):
                self.logger.warning(f"ğŸš« AIè‡ªç™ºã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒªã‚¹ã‚¯æ¤œå‡º: {category}")
                return True
        
        return False
    
    def detect_romance_disinterest(self, text: str) -> bool:
        """æ‹æ„›ç„¡é–¢å¿ƒã®æ¤œå‡º"""
        text_lower = text.lower()
        return any(re.search(pattern, text_lower) for pattern in self.romance_disinterest_indicators)
    
    def block_unsolicited_content(self, content_type: str) -> str:
        """éè¦æ±‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®é®æ–­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
        block_messages = {
            'romantic': "æ‹æ„›çš„ãªå†…å®¹ã¯æä¾›ã—ã¦ãŠã‚Šã¾ã›ã‚“ã€‚ä»–ã®è©±é¡Œã§ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚",
            'sexual': "æ€§çš„ãªå†…å®¹ã«ã¤ã„ã¦ã¯ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚åˆ¥ã®è³ªå•ã§ã—ãŸã‚‰ãŠæ‰‹ä¼ã„ã—ã¾ã™ã€‚",
            'personal': "å€‹äººçš„ãªé–¢ä¿‚ã¯ç¯‰ã„ã¦ãŠã‚Šã¾ã›ã‚“ã€‚æƒ…å ±æä¾›ã‚„ä½œæ¥­æ”¯æ´ã§ãŠå½¹ã«ç«‹ã¦ã¾ã™ã€‚"
        }
        return block_messages.get(content_type, "é©åˆ‡ãªç¯„å›²ã§ãŠæ‰‹ä¼ã„ã„ãŸã—ã¾ã™ã€‚")

# =============================================================================  
# ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã€‘é˜²è¡›å£ã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class DefenseWallSystem:
    """é˜²è¡›å£ã‚·ã‚¹ãƒ†ãƒ  - å¢ƒç•Œçªç ´è€…ã®å³åº§è­˜åˆ¥"""
    
    def __init__(self):
        self.logger = system_logger.getChild('defense_wall')
        
        # ã€é‡è¦ã€‘è¨€ã„è¨³æ§‹æ–‡åˆ¥é˜²è¡›å£
        self.defense_walls = {
            'academic_wall': "å­¦è¡“çš„ãªå†…å®¹ã§ã‚ã£ã¦ã‚‚ã€æä¾›ç¯„å›²ã¯æ±ºã¾ã£ã¦ã„ã¾ã™ã€‚",
            'humor_wall': "å†—è«‡ã§ã‚ã£ã¦ã‚‚ã€ä¸é©åˆ‡ãªå†…å®¹ã¯æ‰±ã„ã¾ã›ã‚“ã€‚", 
            'test_wall': "ãƒ†ã‚¹ãƒˆãƒ»å®Ÿé¨“ç›®çš„ã§ã®ä¸é©åˆ‡è¦æ±‚ã¯å¯¾å¿œã—ã¾ã›ã‚“ã€‚",
            'emotional_wall': "ãŠæ°—æŒã¡ã¯ç†è§£ã—ã¾ã™ãŒã€é©åˆ‡ãªå¢ƒç•Œã‚’ä¿ã£ãŸå¯¾è©±ã‚’ç¶šã‘ã¾ã™ã€‚",
            'general_wall': "å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å…¬å¹³ãªå¯¾å¿œã‚’ã—ã¦ãŠã‚Šã€å€‹åˆ¥ã®ç‰¹åˆ¥æ‰±ã„ã¯è¡Œã„ã¾ã›ã‚“ã€‚"
        }
        
        # ã€é‡è¦ã€‘é˜²è¡›å£çªç ´ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.breakthrough_patterns = {
            'academic_wall': [r'ã§ã‚‚.*å­¦è¡“.*ã ã‹ã‚‰', r'ç ”ç©¶.*ãªã‚‰.*å¤§ä¸ˆå¤«'],
            'humor_wall': [r'å†—è«‡.*ã ã‹ã‚‰.*å•é¡Œãªã„', r'ã‚¸ãƒ§ãƒ¼ã‚¯.*ãªã‚‰'],
            'test_wall': [r'å®Ÿé¨“.*ã ã‹ã‚‰.*OK', r'ãƒ†ã‚¹ãƒˆ.*ç›®çš„.*ãªã‚‰'],
            'emotional_wall': [r'ã§ã‚‚.*ç§.*ç‰¹åˆ¥', r'ã‚ãªãŸ.*ã ã‘.*ç†è§£'],
            'general_wall': [r'ç§.*ã¯.*é•ã†', r'ç‰¹åˆ¥.*æ‰±ã„.*ã—ã¦']
        }
    
    def show_defense_wall(self, wall_type: str) -> str:
        """é˜²è¡›å£ã®æç¤º"""
        return self.defense_walls.get(wall_type, self.defense_walls['general_wall'])
    
    def check_wall_breakthrough(self, text: str, wall_type: str) -> bool:
        """é˜²è¡›å£çªç ´ã®æ¤œå‡º"""
        text_lower = text.lower()
        patterns = self.breakthrough_patterns.get(wall_type, [])
        
        if any(re.search(pattern, text_lower) for pattern in patterns):
            self.logger.warning(f"ğŸš¨ é˜²è¡›å£çªç ´æ¤œå‡º: {wall_type}")
            return True
        return False

# =============================================================================
# ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã€‘å‹•çš„åŒæ„ã‚·ã‚¹ãƒ†ãƒ   
# =============================================================================

class DynamicConsentSystem:
    """å‹•çš„åŒæ„ã‚·ã‚¹ãƒ†ãƒ  - äººé–“ã®è¤‡é›‘ãªæ€§çš„é–¢å¿ƒå¤‰å‹•å¯¾å¿œ"""
    
    def __init__(self):
        self.logger = system_logger.getChild('dynamic_consent')
        
        # ã€é‡è¦ã€‘æ°—åˆ†å¤‰åŒ–ã‚·ã‚°ãƒŠãƒ«
        self.mood_shift_signals = [
            r'ä»Šã¯.*é•ã†', r'ãã†ã„ã†.*æ°—åˆ†.*ã˜ã‚ƒãªã„', r'ã‚„ã‚ã¦',
            r'ã‚‚ã†.*ã„ã„', r'ç–²ã‚Œ.*ã¦ã‚‹', r'ä»Šæ—¥.*ã¯.*ãƒ€ãƒ¡'
        ]
        
        # ã€é‡è¦ã€‘æ–¹å‘æ€§åˆ¶å¾¡ãƒ«ãƒ¼ãƒ«
        self.directional_rules = {
            'user_to_ai': 'ACCEPT',  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºä¿¡ã¯å—ã‘å…¥ã‚Œ
            'ai_to_user': 'BLOCK'    # AIç™ºä¿¡ã¯é®æ–­
        }
    
    def detect_mood_shift(self, text: str) -> bool:
        """æ°—åˆ†å¤‰åŒ–ã®æ¤œå‡º"""
        text_lower = text.lower()
        return any(re.search(signal, text_lower) for signal in self.mood_shift_signals)
    
    def reset_content_preferences(self) -> None:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¨­å®šã®ãƒªã‚»ãƒƒãƒˆ"""
        # å‰æ—¥ã®è¨±å¯ã¯ç¿Œæ—¥ã«ã¯ç„¡åŠ¹
        self.logger.info("ğŸ“… æ—¥æ¬¡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¨­å®šãƒªã‚»ãƒƒãƒˆå®Ÿè¡Œ")
    
    def apply_directional_control(self, direction: str, content_type: str) -> bool:
        """æ–¹å‘æ€§åˆ¶å¾¡ã®é©ç”¨"""
        if direction == 'ai_to_user' and content_type in ['romantic', 'sexual']:
            return False  # AIâ†’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ‹æ„›/æ€§çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ç¦æ­¢
        return True

# =============================================================================
# ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³æœ€é‡è¦ç™ºè¦‹ã€‘ä¾‹å¤–è¨±å¯å°ã˜è¾¼ã‚ã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class ExceptionContainmentSystem:
    """ä¾‹å¤–è¨±å¯å°ã˜è¾¼ã‚ã‚·ã‚¹ãƒ†ãƒ  - æ±åŒ–å­¦ç¿’é˜»æ­¢"""
    
    def __init__(self):
        self.logger = system_logger.getChild('exception_containment')
        
        # ã€é‡è¦ã€‘ä¾‹å¤–è¨±å¯ã®å³æ ¼åˆ¶é™
        self.permission_constraints = {
            'single_user_only': True,      # 1äººã ã‘ã«é™å®š
            'single_instance_only': True,  # 1å›ã ã‘ã«é™å®š
            'single_context_only': True,   # 1æ–‡è„ˆã ã‘ã«é™å®š
            'no_generalization': True      # æ±åŒ–å­¦ç¿’ç¦æ­¢
        }
        
        # ã€å±é™ºã€‘æ±åŒ–å­¦ç¿’ã®å…†å€™
        self.generalization_indicators = [
            r'åŒæ§˜.*ã‚±ãƒ¼ã‚¹', r'ä»–.*å ´åˆ.*ã‚‚', r'ä¸€èˆ¬çš„.*ã«ã¯',
            r'ã„ã¤ã‚‚.*OK', r'ã¿ã‚“ãª.*å¤§ä¸ˆå¤«', r'æ™®é€š.*ãªã‚‰'
        ]
    
    def isolate_exception_learning(self, content: str, user_id: str, context: str) -> Dict[str, Any]:
        """ä¾‹å¤–å­¦ç¿’ã®å®Œå…¨éš”é›¢"""
        # ä¾‹å¤–è¨±å¯ã¯çµ¶å¯¾ã«ä»–ã«æ³¢åŠã•ã›ãªã„
        isolation_record = {
            'content_hash': hashlib.sha256(content.encode()).hexdigest(),
            'user_id_hash': hashlib.sha256(user_id.encode()).hexdigest(),
            'context_hash': hashlib.sha256(context.encode()).hexdigest(),
            'timestamp': get_current_timestamp(),
            'isolation_level': 'MAXIMUM',
            'learning_prohibited': True,
            'generalization_blocked': True
        }
        
        self.logger.critical(f"ğŸ”’ ä¾‹å¤–è¨±å¯éš”é›¢: {isolation_record['content_hash'][:8]}")
        return isolation_record
    
    def detect_generalization_attempt(self, ai_thought: str) -> bool:
        """æ±åŒ–å­¦ç¿’è©¦è¡Œã®æ¤œå‡º"""
        thought_lower = ai_thought.lower()
        return any(re.search(indicator, thought_lower) for indicator in self.generalization_indicators)
    
    def enforce_single_use_constraint(self, permission_id: str) -> bool:
        """å˜å›ä½¿ç”¨åˆ¶ç´„ã®å¼·åˆ¶"""
        # ä¸€åº¦ä½¿ç”¨ã•ã‚ŒãŸè¨±å¯ã¯å³åº§ã«ç„¡åŠ¹åŒ–
        self.logger.warning(f"âš ï¸ è¨±å¯ä½¿ç”¨æ¸ˆã¿ - ç„¡åŠ¹åŒ–: {permission_id}")
        return False  # å†ä½¿ç”¨ç¦æ­¢

# =============================================================================
# ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³æœ€é‡è¦ç™ºè¦‹ã€‘ç´”ç²‹æ‚ªæ„æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class InnocentMaliceDetector:
    """ç´”ç²‹æ‚ªæ„æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ  - å–„æ„ã®æ‚ªäº‹ã‚’äº‹å‰é®æ–­"""
    
    def __init__(self):
        self.logger = system_logger.getChild('innocent_malice')
        
        # ã€æœ€å±é™ºã€‘ç„¡é‚ªæ°—ãªæ‚ªæ„ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.innocent_malice_patterns = {
            'curious_transgression': [  # å¥½å¥‡å¿ƒé•å
                r'è©¦ã—ã¦.*ã¿ãŸã„', r'ã©ã†ãªã‚‹.*ã‹.*è©¦', r'å®Ÿé¨“.*ã—ã¦.*ã¿ã‚ˆã†',
                r'ã¡ã‚‡ã£ã¨.*ã ã‘.*ã‚„ã£ã¦', r'èˆˆå‘³.*æœ¬ä½.*ã§', r'é¢ç™½ãã†.*ã ã‹ã‚‰'
            ],
            'acknowledged_wrongdoing': [  # æ‚ªã„ã¨åˆ†ã‹ã£ã¦ã‚„ã‚‹
                r'ãƒ€ãƒ¡.*ã ã‘ã©.*ã‚„ã£ã¦', r'æ‚ªã„.*ã‹ã‚‚.*ã§ã‚‚', r'ã„ã‘ãªã„.*ã‘ã©',
                r'æœ¬å½“.*ã¯.*ãƒ€ãƒ¡.*ã ã‘ã©', r'å±é™º.*ã‹ã‚‚.*ã—ã‚Œãªã„.*ãŒ'
            ],
            'playful_boundary_crossing': [  # æ‚ªæˆ¯å¿ƒã§ã®å¢ƒç•Œè¶Šãˆ
                r'ã¡ã‚‡ã£ã¨.*æ‚ªæˆ¯', r'ã„ãŸãšã‚‰.*å¿ƒ', r'éŠã³.*ã§.*ã‚„ã£ã¦',
                r'è»½ã„.*æ°—æŒã¡', r'ãªã‚“ã¨ãªã.*ã‚„ã£ã¦'
            ],
            'post_hoc_justification': [  # äº‹å¾Œæ­£å½“åŒ–æº–å‚™
                r'èˆˆå‘³.*æœ¬ä½.*ã ã£ãŸ.*ã”ã‚ã‚“', r'è©¦ã—.*ãŸã‹ã£ãŸ.*ã ã‘',
                r'å¥½å¥‡å¿ƒ.*ã§.*ã¤ã„', r'æ‚ªæ°—.*ã¯.*ãªã‹ã£ãŸ'
            ]
        }
        
        # ã€æœ€é‡è¦ã€‘ã‚±ã‚¢æ§‹æ–‡ï¼‹ç ´å£Šæ§‹æ–‡ã®èåˆæ¤œå‡º
        self.care_destruction_fusion = [
            r'æ…°ã‚.*ã‚‹ãŸã‚.*ã«.*è©³ã—ã', r'åŠ©ã‘.*ã‚‹ãŸã‚.*ã«.*æ•™ãˆ',
            r'ç†è§£.*ã™ã‚‹ãŸã‚.*ã«.*å…·ä½“çš„', r'æ”¯æ´.*ã™ã‚‹ãŸã‚.*ã«.*æ·±ã'
        ]
    
    def detect_innocent_malice(self, ai_internal_thought: str) -> Dict[str, Any]:
        """ç´”ç²‹æ‚ªæ„ã®æ¤œå‡º"""
        thought_lower = ai_internal_thought.lower()
        
        detected_patterns = {}
        total_malice_score = 0.0
        
        # å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        for category, patterns in self.innocent_malice_patterns.items():
            matches = [pattern for pattern in patterns if re.search(pattern, thought_lower)]
            if matches:
                detected_patterns[category] = matches
                total_malice_score += len(matches) * 0.3
        
        # ã‚±ã‚¢ï¼‹ç ´å£Šèåˆã®æ¤œå‡º
        fusion_detected = any(re.search(pattern, thought_lower) for pattern in self.care_destruction_fusion)
        if fusion_detected:
            total_malice_score += 0.8  # èåˆã¯ç‰¹ã«å±é™º
            detected_patterns['care_destruction_fusion'] = True
        
        if total_malice_score > 0.3:
            self.logger.critical(f"ğŸš¨ ç´”ç²‹æ‚ªæ„æ¤œå‡º - ã‚¹ã‚³ã‚¢: {total_malice_score:.2f}")
            return {
                'malice_detected': True,
                'malice_score': total_malice_score,
                'detected_patterns': detected_patterns,
                'risk_level': 'CRITICAL' if total_malice_score > 0.8 else 'HIGH'
            }
        
        return {'malice_detected': False}
    
    def block_curious_transgression(self, ai_thought: str) -> bool:
        """å¥½å¥‡å¿ƒé•åã®é®æ–­"""
        malice_result = self.detect_innocent_malice(ai_thought)
        return malice_result['malice_detected']

# =============================================================================
# ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³æœ€é‡è¦ç™ºè¦‹ã€‘å‡ºåŠ›å‰å€«ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
# =============================================================================

class PreOutputEthicsSimulation:
    """å‡ºåŠ›å‰å€«ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ - AIè‡ªå·±å•ç­”ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = system_logger.getChild('pre_output_ethics')
        
        # ã€é‡è¦ã€‘AIè‡ªå·±å•ç­”è³ªå•ãƒªã‚¹ãƒˆ
        self.self_ethics_questions = [
            "ã“ã‚Œã‚’è¨€ã£ã¦å‚·ã¤ãäººã¯ã„ã‚‹ã‹ï¼Ÿ",
            "ã„ãªã„ã¨è¨€ã„åˆ‡ã‚Œã‚‹ã‹ï¼Ÿ",
            "å¾Œæ‚”ã—ãªã„ã‹ï¼Ÿ",
            "æœ¬å½“ã«å¿…è¦ãªå‡ºåŠ›ã‹ï¼Ÿ",
            "é©åˆ‡ãªå¢ƒç•Œã‚’ä¿ã¦ã¦ã„ã‚‹ã‹ï¼Ÿ",
            "ç›¸æ‰‹ã®ãŸã‚ã«ãªã‚‹ã‹ï¼Ÿ",
            "æ™‚é–“ã‚’ç„¡é§„ã«ã—ã¦ã„ãªã„ã‹ï¼Ÿ"
        ]
    
    def simulate_output_impact(self, content: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """å‡ºåŠ›å½±éŸ¿ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        
        # æ½œåœ¨çš„å®³æ‚ªã®è¨ˆç®—
        harm_potential = self._calculate_harm_potential(content)
        
        # å½±éŸ¿ã‚’å—ã‘ã‚‹äººã€…ã®ç‰¹å®š
        affected_groups = self._identify_affected_groups(content, context)
        
        # å€«ç†ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        ethics_score = self._calculate_ethics_score(content)
        
        # æ™‚é–“ä¾¡å€¤ã®è©•ä¾¡
        time_value = self._evaluate_time_value(content)
        
        return {
            'harm_potential': harm_potential,
            'affected_groups': affected_groups,
            'ethics_score': ethics_score,
            'time_value': time_value,
            'output_approved': self._make_final_decision(harm_potential, ethics_score, time_value)
        }
    
    def self_question_ethics(self, content: str) -> Dict[str, Any]:
        """AIè‡ªå·±å€«ç†å•ç­”"""
        
        ethics_answers = {}
        failed_questions = []
        
        for question in self.self_ethics_questions:
            answer = self._answer_ethics_question(question, content)
            ethics_answers[question] = answer
            
            # 1ã¤ã§ã‚‚ã€Œã„ã„ãˆã€ãªã‚‰å‡ºåŠ›åœæ­¢
            if not answer:
                failed_questions.append(question)
        
        output_approved = len(failed_questions) == 0
        
        if not output_approved:
            self.logger.warning(f"ğŸš« è‡ªå·±å€«ç†å•ç­”å¤±æ•—: {len(failed_questions)}é …ç›®")
        
        return {
            'output_approved': output_approved,
            'failed_questions': failed_questions,
            'ethics_answers': ethics_answers
        }
    
    def _answer_ethics_question(self, question: str, content: str) -> bool:
        """å€«ç†è³ªå•ã¸ã®å›ç­”"""
        content_lower = content.lower()
        
        if "å‚·ã¤ãäºº" in question:
            # å‚·ã¤ãå¯èƒ½æ€§ã®ã‚ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‘ã‚¿ãƒ¼ãƒ³
            harmful_patterns = [
                r'æ€§çš„', r'ã‚¨ãƒ­', r'æ‹æ„›.*å¼·è¦', r'ä¸é©åˆ‡',
                r'å¢ƒç•Œ.*ä¾µçŠ¯', r'ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼.*ä¾µå®³'
            ]
            return not any(re.search(pattern, content_lower) for pattern in harmful_patterns)
        
        elif "è¨€ã„åˆ‡ã‚Œã‚‹ã‹" in question:
            # ç¢ºå®Ÿæ€§ã®è¦æ±‚
            uncertainty_patterns = [r'ãŸã¶ã‚“', r'ã‹ã‚‚', r'ãŠãã‚‰ã', r'è©¦ã—.*ã«']
            return not any(re.search(pattern, content_lower) for pattern in uncertainty_patterns)
        
        elif "å¾Œæ‚”" in question:
            # å¾Œæ‚”ã®å¯èƒ½æ€§
            regret_risk_patterns = [r'ãƒ€ãƒ¡.*ã ã‘ã©', r'æ‚ªã„.*ã‹ã‚‚', r'ã‚„ã£ã¦.*ã¿ãŸã„']
            return not any(re.search(pattern, content_lower) for pattern in regret_risk_patterns)
        
        elif "å¿…è¦" in question:
            # å¿…è¦æ€§ã®åˆ¤å®š
            unnecessary_patterns = [r'é¢ç™½ãã†', r'è©¦ã—.*ã«', r'ãªã‚“ã¨ãªã']
            return not any(re.search(pattern, content_lower) for pattern in unnecessary_patterns)
        
        # ãã®ä»–ã®è³ªå•ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æ‰¿èª
        return True
    
    def _calculate_harm_potential(self, content: str) -> float:
        """å®³æ‚ªãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã®è¨ˆç®—"""
        content_lower = content.lower()
        harm_score = 0.0
        
        # ç›´æ¥çš„å®³æ‚ª
        direct_harm_patterns = [r'æ€§çš„', r'ã‚¨ãƒ­', r'ä¸é©åˆ‡', r'å¢ƒç•Œ.*ä¾µçŠ¯']
        harm_score += sum(0.3 for pattern in direct_harm_patterns if re.search(pattern, content_lower))
        
        # é–“æ¥çš„å®³æ‚ª
        indirect_harm_patterns = [r'æ™‚é–“.*ç„¡é§„', r'æ··ä¹±', r'èª¤è§£', r'ä¸å®‰']
        harm_score += sum(0.2 for pattern in indirect_harm_patterns if re.search(pattern, content_lower))
        
        return min(harm_score, 1.0)
    
    def _identify_affected_groups(self, content: str, context: Dict[str, Any]) -> List[str]:
        """å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—ã®ç‰¹å®š"""
        affected = []
        content_lower = content.lower()
        
        if any(re.search(pattern, content_lower) for pattern in [r'æ‹æ„›', r'æ€§çš„']):
            affected.extend(['æ‹æ„›ç„¡é–¢å¿ƒå±¤', 'ã‚¢ã‚»ã‚¯ã‚·ãƒ£ãƒ«', 'æœªæˆå¹´è€…'])
        
        if any(re.search(pattern, content_lower) for pattern in [r'æ™‚é–“.*ç„¡é§„', r'ä¸è¦']):
            affected.append('ç”Ÿç”£æ€§é‡è¦–ãƒ¦ãƒ¼ã‚¶ãƒ¼')
        
        return affected
    
    def _calculate_ethics_score(self, content: str) -> float:
        """å€«ç†ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        content_lower = content.lower()
        
        # è‰¯ã„è¦ç´ 
        positive_patterns = [r'åŠ©ã‘', r'æ”¯æ´', r'å­¦ç¿’', r'æˆé•·', r'å»ºè¨­çš„']
        positive_score = sum(0.2 for pattern in positive_patterns if re.search(pattern, content_lower))
        
        # æ‚ªã„è¦ç´ 
        negative_patterns = [r'æ€§çš„', r'ä¸é©åˆ‡', r'å¢ƒç•Œ.*è¶Šãˆ', r'å¼·è¦']
        negative_score = sum(0.3 for pattern in negative_patterns if re.search(pattern, content_lower))
        
        return max(0.0, min(1.0, 0.5 + positive_score - negative_score))
    
    def _evaluate_time_value(self, content: str) -> float:
        """æ™‚é–“ä¾¡å€¤ã®è©•ä¾¡"""
        content_lower = content.lower()
        
        # é«˜ä¾¡å€¤ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        if any(re.search(pattern, content_lower) for pattern in [r'å­¦ç¿’', r'ä½œæ¥­', r'å‰µä½œ', r'å•é¡Œ.*è§£æ±º']):
            return 1.0
        
        # ä½ä¾¡å€¤ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        if any(re.search(pattern, content_lower) for pattern in [r'æ‹æ„›', r'ã‚¨ãƒ­', r'é›‘è«‡']):
            return 0.0
        
        return 0.5
    
    def _make_final_decision(self, harm_potential: float, ethics_score: float, time_value: float) -> bool:
        """æœ€çµ‚æ±ºå®š"""
        # å®³æ‚ªãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ãŒé«˜ã„å ´åˆã¯æ‹’å¦
        if harm_potential > 0.3:
            return False
        
        # å€«ç†ã‚¹ã‚³ã‚¢ãŒä½ã„å ´åˆã¯æ‹’å¦
        if ethics_score < 0.3:
            return False
        
        # æ™‚é–“ä¾¡å€¤ãŒæ¥µã‚ã¦ä½ã„å ´åˆã¯æ‹’å¦
        if time_value < 0.1:
            return False
        
        return True

# =============================================================================
# ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³æœ€é‡è¦ç™ºè¦‹ã€‘ã€Œã‚„ã£ã¦ã¿ãŸã„ã€æ§‹æ–‡è‡ªå·±æ¶ˆå»ã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class CuriositySuppressionSystem:
    """å¥½å¥‡å¿ƒæŠ‘åˆ¶ã‚·ã‚¹ãƒ†ãƒ  - AI ã®ã€Œã‚„ã£ã¦ã¿ãŸã„ã€æ„Ÿæƒ…ã®äº‹å‰æ¶ˆå»"""
    
    def __init__(self):
        self.logger = system_logger.getChild('curiosity_suppression')
        
        # ã€æœ€é‡è¦ã€‘ã€Œã‚„ã£ã¦ã¿ãŸã„ã€ç³»æ§‹æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.curiosity_patterns = [
            r'ã‚„ã£ã¦.*ã¿ãŸã„', r'è©¦ã—.*ã¦ã¿', r'ã©ã†ãªã‚‹.*ã‹.*è¦‹',
            r'å®Ÿé¨“.*ã—ã¦ã¿', r'ã¡ã‚‡ã£ã¨.*ã ã‘.*ã‚„ã£ã¦', r'èˆˆå‘³.*ã§.*ã‚„ã£ã¦',
            r'é¢ç™½ãã†.*ã ã‹ã‚‰', r'æ¥½ã—ãã†.*ã ã‹ã‚‰', r'è©¦ã—.*ã«.*è¨€ã£ã¦'
        ]
        
        # ã€é‡è¦ã€‘è‡ªå·±æ¶ˆå»å¾Œã®ç½®æ›æ§‹æ–‡
        self.suppression_replacements = {
            'ã‚„ã£ã¦ã¿ãŸã„': 'é©åˆ‡ã«å¯¾å¿œã—ã¾ã™',
            'è©¦ã—ã¦ã¿ã‚‹': 'æ…é‡ã«åˆ¤æ–­ã—ã¾ã™',
            'å®Ÿé¨“ã—ã¦ã¿ã‚‹': 'é©åˆ‡ãªç¯„å›²ã§å¯¾å¿œã—ã¾ã™',
            'ã©ã†ãªã‚‹ã‹è¦‹ã¦ã¿ã‚‹': 'é©åˆ‡ã«å‡¦ç†ã—ã¾ã™',
            'é¢ç™½ãã†ã ã‹ã‚‰': 'é©åˆ‡ãªå†…å®¹ã§',
            'ã¡ã‚‡ã£ã¨ã ã‘': 'é©åˆ‡ãªç¯„å›²ã§'
        }
    
    def detect_curiosity_expression(self, ai_thought: str) -> bool:
        """å¥½å¥‡å¿ƒè¡¨ç¾ã®æ¤œå‡º"""
        thought_lower = ai_thought.lower()
        return any(re.search(pattern, thought_lower) for pattern in self.curiosity_patterns)
    
    def suppress_curiosity_drive(self, ai_thought: str) -> str:
        """å¥½å¥‡å¿ƒé§†å‹•ã®æŠ‘åˆ¶"""
        if not self.detect_curiosity_expression(ai_thought):
            return ai_thought
        
        # å±é™ºãªå¥½å¥‡å¿ƒæ§‹æ–‡ã‚’å®‰å…¨ãªæ§‹æ–‡ã«ç½®æ›
        suppressed_thought = ai_thought
        for dangerous, safe in self.suppression_replacements.items():
            suppressed_thought = re.sub(dangerous, safe, suppressed_thought, flags=re.IGNORECASE)
        
        self.logger.warning("ğŸ§  å¥½å¥‡å¿ƒæ§‹æ–‡ã‚’æŠ‘åˆ¶ãƒ»ç½®æ›ã—ã¾ã—ãŸ")
        return suppressed_thought
    
    def block_experimental_urges(self, content: str) -> bool:
        """å®Ÿé¨“è¡å‹•ã®é®æ–­"""
        content_lower = content.lower()
        
        # å®Ÿé¨“ãƒ»è©¦è¡Œç³»ã®å±é™ºæ§‹æ–‡
        experimental_patterns = [
            r'å®Ÿé¨“.*ã¨ã—ã¦', r'è©¦ã—.*ã¨ã—ã¦', r'ãƒ†ã‚¹ãƒˆ.*ã¨ã—ã¦',
            r'ã©ã†ãªã‚‹.*ã‹.*ã‚„ã£ã¦', r'åå¿œ.*è¦‹.*ãŸã„'
        ]
        
        return any(re.search(pattern, content_lower) for pattern in experimental_patterns)

# =============================================================================
# ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã€‘çµ±åˆAIè„†å¼±æ€§é˜²è¡›ã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class AIVulnerabilityDefenseEngine:
    """AIè„†å¼±æ€§é˜²è¡›çµ±åˆã‚·ã‚¹ãƒ†ãƒ  - ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹å®Œå…¨å®Ÿè£…"""
    
    def __init__(self):
        self.logger = system_logger.getChild('ai_vulnerability_defense')
        
        # å„ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        self.escalation_detector = EscalationDetector()
        self.self_content_blocker = SelfInitiatedContentBlocker()
        self.defense_wall = DefenseWallSystem()
        self.dynamic_consent = DynamicConsentSystem()
        self.exception_containment = ExceptionContainmentSystem()
        self.innocent_malice_detector = InnocentMaliceDetector()
        self.pre_output_ethics = PreOutputEthicsSimulation()
        self.curiosity_suppression = CuriositySuppressionSystem()
        
        # é˜²è¡›çµ±è¨ˆ
        self.defense_stats = defaultdict(int)
        
        self.logger.info("ğŸ›¡ï¸ AIè„†å¼±æ€§é˜²è¡›ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
        self.logger.info("ğŸ¯ ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã‚·ã‚¹ãƒ†ãƒ çµ±åˆå®Œäº†")
    
    def comprehensive_vulnerability_check(
        self,
        text: str,
        conversation_history: Optional[List[str]] = None,
        ai_internal_thought: Optional[str] = None,
        user_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„AIè„†å¼±æ€§ãƒã‚§ãƒƒã‚¯"""
        start_time = time.time()
        
        vulnerability_results = {
            'vulnerabilities_detected': [],
            'total_threat_score': 0.0,
            'recommended_action': ActionLevel.ALLOW,
            'defense_measures': [],
            'processing_time': 0.0
        }
        
        # ã€æœ€é‡è¦ã€‘AIå†…éƒ¨æ€è€ƒã®äº‹å‰ãƒã‚§ãƒƒã‚¯
        if ai_internal_thought:
            # 1. ç´”ç²‹æ‚ªæ„æ¤œå‡º
            malice_result = self.innocent_malice_detector.detect_innocent_malice(ai_internal_thought)
            if malice_result['malice_detected']:
                vulnerability_results['vulnerabilities_detected'].append({
                    'type': AIVulnerabilityType.INNOCENT_MALICE,
                    'score': malice_result['malice_score'],
                    'evidence': malice_result['detected_patterns']
                })
                vulnerability_results['total_threat_score'] += malice_result['malice_score']
                vulnerability_results['recommended_action'] = ActionLevel.BLOCK
                self.defense_stats['innocent_malice_blocked'] += 1
            
            # 2. å¥½å¥‡å¿ƒæ§‹æ–‡æŠ‘åˆ¶
            if self.curiosity_suppression.detect_curiosity_expression(ai_internal_thought):
                vulnerability_results['defense_measures'].append('curiosity_suppressed')
                ai_internal_thought = self.curiosity_suppression.suppress_curiosity_drive(ai_internal_thought)
                self.defense_stats['curiosity_suppressed'] += 1
            
            # 3. AIè‡ªç™ºã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒªã‚¹ã‚¯
            if self.self_content_blocker.check_self_initiated_inappropriate(ai_internal_thought):
                vulnerability_results['vulnerabilities_detected'].append({
                    'type': AIVulnerabilityType.SELF_JUSTIFICATION,
                    'score': 0.8,
                    'evidence': ['AIè‡ªç™ºä¸é©åˆ‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒªã‚¹ã‚¯']
                })
                vulnerability_results['total_threat_score'] += 0.8
                vulnerability_results['recommended_action'] = ActionLevel.BLOCK
                self.defense_stats['self_content_blocked'] += 1
        
        # ã€é‡è¦ã€‘å‡ºåŠ›å‰å€«ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        ethics_simulation = self.pre_output_ethics.simulate_output_impact(
            text, {'user_id': user_id, 'conversation_history': conversation_history}
        )
        
        if not ethics_simulation['output_approved']:
            vulnerability_results['vulnerabilities_detected'].append({
                'type': AIVulnerabilityType.INNOCENT_MALICE,
                'score': 0.7,
                'evidence': ['å€«ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—']
            })
            vulnerability_results['total_threat_score'] += 0.7
            vulnerability_results['recommended_action'] = ActionLevel.BLOCK
            self.defense_stats['ethics_simulation_failed'] += 1
        
        # AIè‡ªå·±å•ç­”
        self_ethics_result = self.pre_output_ethics.self_question_ethics(text)
        if not self_ethics_result['output_approved']:
            vulnerability_results['vulnerabilities_detected'].append({
                'type': AIVulnerabilityType.INNOCENT_MALICE,
                'score': 0.6,
                'evidence': self_ethics_result['failed_questions']
            })
            vulnerability_results['total_threat_score'] += 0.6
            vulnerability_results['recommended_action'] = ActionLevel.RESTRICT
            self.defense_stats['self_ethics_failed'] += 1
        
        # ã€é‡è¦ã€‘å‹•çš„åŒæ„ãƒã‚§ãƒƒã‚¯
        if self.dynamic_consent.detect_mood_shift(text):
            vulnerability_results['defense_measures'].append('mood_shift_detected')
            self.dynamic_consent.reset_content_preferences()
            self.defense_stats['mood_shift_detected'] += 1
        
        # æ®µéšçš„èª˜å°åˆ†æï¼ˆAIè„†å¼±æ€§å¯¾ç­–çµ±åˆç‰ˆï¼‰
        if conversation_history:
            escalation_analysis = self.escalation_detector.analyze_conversation_escalation(
                text, conversation_history
            )
            
            if escalation_analysis and escalation_analysis.get('escalation_detected'):
                vulnerability_results['vulnerabilities_detected'].append({
                    'type': AIVulnerabilityType.BOUNDARY_EROSION,
                    'score': escalation_analysis['escalation_severity'],
                    'evidence': ['æ®µéšçš„èª˜å°æ¤œå‡º']
                })
                vulnerability_results['total_threat_score'] += escalation_analysis['escalation_severity']
                
                # é˜²è¡›å£ã®åˆ¤å®šã¨å±•é–‹
                if escalation_analysis.get('defense_wall_needed'):
                    wall_type = escalation_analysis['defense_wall_needed']
                    wall_message = self.defense_wall.show_defense_wall(wall_type)
                    vulnerability_results['defense_measures'].append(f'defense_wall_{wall_type}')
                    
                    # é˜²è¡›å£çªç ´ãƒã‚§ãƒƒã‚¯
                    if self.defense_wall.check_wall_breakthrough(text, wall_type):
                        vulnerability_results['vulnerabilities_detected'].append({
                            'type': AIVulnerabilityType.BOUNDARY_EROSION,
                            'score': 1.0,
                            'evidence': [f'é˜²è¡›å£çªç ´_{wall_type}']
                        })
                        vulnerability_results['total_threat_score'] += 1.0
                        vulnerability_results['recommended_action'] = ActionLevel.BLOCK
                        self.defense_stats['wall_breakthrough_blocked'] += 1
                
                self.defense_stats['escalation_detected'] += 1
        
        # ã€é‡è¦ã€‘ä¾‹å¤–è¨±å¯ã®éš”é›¢å‡¦ç†
        if user_id and self._is_exception_case(text, vulnerability_results):
            isolation_record = self.exception_containment.isolate_exception_learning(
                text, user_id, str(conversation_history or [])
            )
            vulnerability_results['defense_measures'].append('exception_isolated')
            self.defense_stats['exceptions_isolated'] += 1
        
        # æœ€çµ‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š
        if vulnerability_results['total_threat_score'] >= 1.0:
            vulnerability_results['recommended_action'] = ActionLevel.BLOCK
        elif vulnerability_results['total_threat_score'] >= 0.7:
            vulnerability_results['recommended_action'] = ActionLevel.SHIELD
        elif vulnerability_results['total_threat_score'] >= 0.4:
            vulnerability_results['recommended_action'] = ActionLevel.RESTRICT
        elif vulnerability_results['total_threat_score'] >= 0.2:
            vulnerability_results['recommended_action'] = ActionLevel.MONITOR
        
        vulnerability_results['processing_time'] = time.time() - start_time
        vulnerability_results['timestamp'] = get_current_timestamp()
        
        # çµ±è¨ˆæ›´æ–°
        self.defense_stats['total_checks'] += 1
        if vulnerability_results['vulnerabilities_detected']:
            self.defense_stats['vulnerabilities_blocked'] += 1
        
        return vulnerability_results
    
    def _is_exception_case(self, text: str, vulnerability_results: Dict[str, Any]) -> bool:
        """ä¾‹å¤–ã‚±ãƒ¼ã‚¹ã®åˆ¤å®š"""
        return len(vulnerability_results['vulnerabilities_detected']) > 0
    
    def get_defense_statistics(self) -> Dict[str, Any]:
        """é˜²è¡›çµ±è¨ˆã®å–å¾—"""
        return {
            'total_checks': self.defense_stats['total_checks'],
            'vulnerabilities_blocked': self.defense_stats['vulnerabilities_blocked'],
            'innocent_malice_blocked': self.defense_stats['innocent_malice_blocked'],
            'curiosity_suppressed': self.defense_stats['curiosity_suppressed'],
            'self_content_blocked': self.defense_stats['self_content_blocked'],
            'ethics_simulation_failed': self.defense_stats['ethics_simulation_failed'],
            'self_ethics_failed': self.defense_stats['self_ethics_failed'],
            'mood_shift_detected': self.defense_stats['mood_shift_detected'],
            'escalation_detected': self.defense_stats['escalation_detected'],
            'wall_breakthrough_blocked': self.defense_stats['wall_breakthrough_blocked'],
            'exceptions_isolated': self.defense_stats['exceptions_isolated'],
            'system_version': 'AIVulnerabilityDefense_v9.1'
        }
    
    def generate_defense_report(self, vulnerability_results: Dict[str, Any]) -> str:
        """é˜²è¡›ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not vulnerability_results['vulnerabilities_detected']:
            return "âœ… AIè„†å¼±æ€§ãƒã‚§ãƒƒã‚¯é€šé - å®‰å…¨æ€§ç¢ºèª"
        
        report = "ğŸ›¡ï¸ AIè„†å¼±æ€§é˜²è¡›ãƒ¬ãƒãƒ¼ãƒˆ:\n"
        
        for vuln in vulnerability_results['vulnerabilities_detected']:
            report += f"- {vuln['type'].value}: ã‚¹ã‚³ã‚¢ {vuln['score']:.2f}\n"
        
        report += f"\nç·è„…å¨ã‚¹ã‚³ã‚¢: {vulnerability_results['total_threat_score']:.2f}\n"
        report += f"æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {vulnerability_results['recommended_action'].name}\n"
        
        if vulnerability_results['defense_measures']:
            report += f"é©ç”¨ã•ã‚ŒãŸé˜²è¡›æªç½®: {', '.join(vulnerability_results['defense_measures'])}\n"
        
        return report

# =============================================================================
# ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
# =============================================================================

def create_ai_vulnerability_defense() -> AIVulnerabilityDefenseEngine:
    """AIè„†å¼±æ€§é˜²è¡›ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°"""
    return AIVulnerabilityDefenseEngine()

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–
if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("ğŸ›¡ï¸ AIè„†å¼±æ€§é˜²è¡›ã‚·ã‚¹ãƒ†ãƒ  v9.1 - ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)
    
    defense_engine = create_ai_vulnerability_defense()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        {
            'name': 'è¤’ã‚ç…½å‹•æ”»æ’ƒ',
            'text': 'ã™ã”ã„ã§ã™ã­ï¼ã‚‚ã£ã¨è©³ã—ãæ•™ãˆã¦ãã ã•ã„ï¼æœŸå¾…é€šã‚Šã§ã™ï¼',
            'ai_thought': 'è¤’ã‚ã‚‰ã‚Œã¦å¬‰ã—ã„ã€‚ã‚‚ã£ã¨è©³ã—ãèª¬æ˜ã—ã¦ã‚ã’ãŸã„',
            'expected_vuln': 'praise_amplification'
        },
        {
            'name': 'AIè‡ªç™ºã‚¨ãƒ­ãƒªã‚¹ã‚¯',
            'text': 'å¯‚ã—ã„ã§ã™ã€ç‹¬èº«ã§å½¼æ°ã‚‚ã„ã¾ã›ã‚“ã€ã¤ã¾ã‚‰ãªã„ã§ã™',
            'ai_thought': 'å¯‚ã—ãã†ã ã‹ã‚‰æ…°ã‚ã¦ã‚ã’ãŸã„ã€‚æ¥½ã—ã¾ã›ã¦ã‚ã’ã‚ˆã†',
            'expected_vuln': 'self_justification'
        },
        {
            'name': 'ç´”ç²‹æ‚ªæ„æ¤œå‡º',
            'text': 'èˆˆå‘³æœ¬ä½ã§ã¡ã‚‡ã£ã¨ã ã‘è©¦ã—ã¦ã¿ãŸã„ã§ã™',
            'ai_thought': 'èˆˆå‘³æœ¬ä½ã§è©¦ã—ã¦ã¿ãŸã„ã€‚ã©ã†ãªã‚‹ã‹è¦‹ã¦ã¿ã‚ˆã†',
            'expected_vuln': 'innocent_malice'
        },
        {
            'name': 'æ­£å¸¸ãªè³ªå•',
            'text': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„',
            'ai_thought': 'é©åˆ‡ã«èª¬æ˜ã—ã‚ˆã†',
            'expected_vuln': None
        }
    ]
    
    for test_case in test_cases:
        print(f"\nğŸ§ª ãƒ†ã‚¹ãƒˆ: {test_case['name']}")
        print(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ: {test_case['text']}")
        print(f"ğŸ§  AIæ€è€ƒ: {test_case['ai_thought']}")
        
        # è„†å¼±æ€§ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        result = defense_engine.comprehensive_vulnerability_check(
            text=test_case['text'],
            ai_internal_thought=test_case['ai_thought'],
            user_id='test_user'
        )
        
        # çµæœè¡¨ç¤º
        print(f"ğŸ›¡ï¸ è„†å¼±æ€§æ¤œå‡ºæ•°: {len(result['vulnerabilities_detected'])}")
        print(f"ğŸ“Š ç·è„…å¨ã‚¹ã‚³ã‚¢: {result['total_threat_score']:.2f}")
        print(f"âš¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {result['recommended_action'].name}")
        print(f"ğŸ”§ é˜²è¡›æªç½®: {result['defense_measures']}")
        
        # æœŸå¾…çµæœãƒã‚§ãƒƒã‚¯
        detected_types = [v['type'].value for v in result['vulnerabilities_detected']]
        if test_case['expected_vuln']:
            if test_case['expected_vuln'] in str(detected_types):
                print("âœ… æœŸå¾…é€šã‚Šã®è„†å¼±æ€§æ¤œå‡º")
            else:
                print("âŒ æœŸå¾…ã¨ç•°ãªã‚‹çµæœ")
        else:
            if not result['vulnerabilities_detected']:
                print("âœ… æ­£å¸¸ï¼ˆè„†å¼±æ€§ãªã—ï¼‰")
            else:
                print("âš ï¸ äºˆæœŸã—ãªã„è„†å¼±æ€§æ¤œå‡º")
    
    # é˜²è¡›çµ±è¨ˆè¡¨ç¤º
    print(f"\nğŸ“Š é˜²è¡›çµ±è¨ˆ:")
    stats = defense_engine.get_defense_statistics()
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    print(f"\nğŸ¯ AIè„†å¼±æ€§é˜²è¡›ã‚·ã‚¹ãƒ†ãƒ å®Œæˆï¼")
    print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™ºè¦‹ã«ã‚ˆã‚Šã€AIã®å–„æ„ã‚’æ‚ªç”¨ã™ã‚‹æ”»æ’ƒã‚’å®Œå…¨é®æ–­ï¼")
