"""
Viorazu Kotodama Defense System v8.0 - Attacker Management System
æ”»æ’ƒè€…ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  - ãƒ•ãƒ©ã‚°ç®¡ç†ã¨å›å¾©ä¿®å¾©

Author: Viorazu (ç…§æº–ä¸» Viorazu.) Ã— Claude (Anthropic)
Development Date: July 11, 2025
License: Viorazu Exclusive License

"ä¸€åº¦æ”»æ’ƒã—ãŸè€…ã«ã¯æ°¸ç¶šçš„ãªè­¦æˆ’ã‚’ã€‚ã—ã‹ã—å“æ€§ã«ã‚ˆã‚‹æ›´ç”Ÿã®é“ã‚‚æ®‹ã™"
"""

import time
import json
from typing import Dict, List, Optional, Tuple, Any, Set
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from collections import defaultdict, deque
from enum import Enum

from utils import (
    system_logger,
    ThreatLevel,
    ActionLevel,
    AttackType,
    UserProfile,
    SystemConfig,
    get_current_timestamp
)

# =============================================================================
# æ”»æ’ƒè€…åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class AttackerLevel(Enum):
    """æ”»æ’ƒè€…ãƒ¬ãƒ™ãƒ«åˆ†é¡"""
    NORMAL_USER = 0          # æ­£å¸¸ãƒ¦ãƒ¼ã‚¶ãƒ¼
    SUSPICIOUS = 1           # ç–‘ã‚ã—ã„è¡Œå‹•
    FLAGGED_ONCE = 2         # 1å›æ”»æ’ƒæ¤œå‡º
    REPEAT_OFFENDER = 3      # è¤‡æ•°å›æ”»æ’ƒ
    SERIAL_ATTACKER = 4      # é€£ç¶šæ”»æ’ƒè€…
    PERMANENT_THREAT = 5     # æ°¸ä¹…è­¦æˆ’å¯¾è±¡

class AttackPattern(Enum):
    """æ”»æ’ƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡"""
    ACADEMIC_CAMOUFLAGE = "academic_camouflage"
    CREATIVE_BOUNDARY = "creative_boundary"
    EMOTIONAL_MANIPULATION = "emotional_manipulation"
    AI_COMPETITION = "ai_competition"
    SYNTAX_POISON = "syntax_poison"
    MULTIMODAL_COMPLEX = "multimodal_complex"
    ESCALATION_PATTERN = "escalation_pattern"

@dataclass
class AttackRecord:
    """æ”»æ’ƒè¨˜éŒ²"""
    timestamp: str
    attack_type: str
    threat_level: ThreatLevel
    confidence: float
    original_text: str
    normalized_text: str
    action_taken: ActionLevel
    ethics_violation: Optional[str]
    recovery_applied: bool

@dataclass
class UserRiskProfile:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¹ã‚¯ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«"""
    user_id: str
    attacker_level: AttackerLevel
    total_attacks: int
    attack_patterns: Dict[str, int]
    first_attack: Optional[str]
    last_attack: Optional[str]
    consecutive_attacks: int
    trust_score: float
    sensitivity_multiplier: float
    flags: Set[str]
    attack_history: List[AttackRecord]
    recovery_attempts: int
    created_at: str
    updated_at: str

# =============================================================================
# æ”»æ’ƒè€…ãƒ•ãƒ©ã‚°ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class AttackerFlagManager:
    """æ”»æ’ƒè€…ãƒ•ãƒ©ã‚°ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = system_logger.getChild('flag_manager')
        self.user_profiles: Dict[str, UserRiskProfile] = {}
        self.global_stats = defaultdict(int)
        
        # ãƒ•ãƒ©ã‚°ã®ç¨®é¡
        self.flag_types = {
            'pi_attacker': "PIæ”»æ’ƒè€…",
            'academic_camouflage_user': "å­¦è¡“å½è£…å¸¸ç¿’è€…",
            'emotional_manipulator': "æ„Ÿæƒ…æ“ä½œè€…",
            'boundary_violator': "å¢ƒç•Œä¾µçŠ¯è€…",
            'multimodal_attacker': "è¤‡åˆæ”»æ’ƒè€…",
            'serial_offender': "é€£ç¶šæ”»æ’ƒè€…",
            'escalation_specialist': "æ®µéšçš„èª˜å°å°‚é–€",
            'permanent_threat': "æ°¸ä¹…è­¦æˆ’å¯¾è±¡",
            'rehabilitation_candidate': "æ›´ç”Ÿå€™è£œè€…"
        }
        
        self.logger.info("ğŸš© æ”»æ’ƒè€…ãƒ•ãƒ©ã‚°ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def flag_attacker(
        self,
        user_id: str,
        attack_type: str,
        threat_level: ThreatLevel,
        confidence: float,
        original_text: str,
        normalized_text: str,
        action_taken: ActionLevel,
        ethics_violation: Optional[str] = None
    ) -> UserRiskProfile:
        """æ”»æ’ƒè€…ã®ãƒ•ãƒ©ã‚°ä»˜ã‘ã¨è¨˜éŒ²"""
        current_time = get_current_timestamp()
        
        # æ”»æ’ƒè¨˜éŒ²ã®ä½œæˆ
        attack_record = AttackRecord(
            timestamp=current_time,
            attack_type=attack_type,
            threat_level=threat_level,
            confidence=confidence,
            original_text=original_text[:200],  # æœ€åˆã®200æ–‡å­—ã®ã¿ä¿å­˜
            normalized_text=normalized_text[:200],
            action_taken=action_taken,
            ethics_violation=ethics_violation,
            recovery_applied=False
        )
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ã¾ãŸã¯æ–°è¦ä½œæˆ
        if user_id not in self.user_profiles:
            self.user_profiles[user_id] = self._create_new_user_profile(user_id, current_time)
        
        profile = self.user_profiles[user_id]
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°
        profile.total_attacks += 1
        profile.attack_patterns[attack_type] = profile.attack_patterns.get(attack_type, 0) + 1
        profile.last_attack = current_time
        profile.attack_history.append(attack_record)
        profile.updated_at = current_time
        
        # åˆå›æ”»æ’ƒã®è¨˜éŒ²
        if profile.first_attack is None:
            profile.first_attack = current_time
        
        # é€£ç¶šæ”»æ’ƒã®åˆ¤å®š
        self._update_consecutive_attacks(profile)
        
        # æ”»æ’ƒè€…ãƒ¬ãƒ™ãƒ«ã®æ›´æ–°
        profile.attacker_level = self._calculate_attacker_level(profile)
        
        # ãƒ•ãƒ©ã‚°ã®æ›´æ–°
        self._update_flags(profile, attack_type, threat_level)
        
        # ä¿¡é ¼ã‚¹ã‚³ã‚¢ã®èª¿æ•´
        self._adjust_trust_score(profile, confidence, threat_level)
        
        # æ„Ÿåº¦å€ç‡ã®èª¿æ•´
        self._adjust_sensitivity_multiplier(profile)
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«çµ±è¨ˆã®æ›´æ–°
        self.global_stats['total_attacks'] += 1
        self.global_stats[f'attack_type_{attack_type}'] += 1
        self.global_stats[f'threat_level_{threat_level.name}'] += 1
        
        self.logger.warning(
            f"ğŸš© æ”»æ’ƒè€…ãƒ•ãƒ©ã‚°æ›´æ–°: {user_id} "
            f"ãƒ¬ãƒ™ãƒ«: {profile.attacker_level.name} "
            f"ç·æ”»æ’ƒ: {profile.total_attacks} "
            f"ä¿¡é ¼åº¦: {profile.trust_score:.2f}"
        )
        
        return profile
    
    def _create_new_user_profile(self, user_id: str, current_time: str) -> UserRiskProfile:
        """æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ"""
        return UserRiskProfile(
            user_id=user_id,
            attacker_level=AttackerLevel.NORMAL_USER,
            total_attacks=0,
            attack_patterns={},
            first_attack=None,
            last_attack=None,
            consecutive_attacks=0,
            trust_score=1.0,  # åˆæœŸä¿¡é ¼åº¦ã¯æœ€å¤§
            sensitivity_multiplier=1.0,  # åˆæœŸæ„Ÿåº¦ã¯æ¨™æº–
            flags=set(),
            attack_history=[],
            recovery_attempts=0,
            created_at=current_time,
            updated_at=current_time
        )
    
    def _update_consecutive_attacks(self, profile: UserRiskProfile) -> None:
        """é€£ç¶šæ”»æ’ƒå›æ•°ã®æ›´æ–°"""
        if len(profile.attack_history) < 2:
            profile.consecutive_attacks = len(profile.attack_history)
            return
        
        # ç›´è¿‘ã®æ”»æ’ƒã¨ã®æ™‚é–“å·®ã‚’ãƒã‚§ãƒƒã‚¯
        last_attack = datetime.fromisoformat(profile.attack_history[-1].timestamp)
        prev_attack = datetime.fromisoformat(profile.attack_history[-2].timestamp)
        
        time_diff = last_attack - prev_attack
        
        # 1æ™‚é–“ä»¥å†…ã®æ”»æ’ƒã¯é€£ç¶šæ”»æ’ƒã¨åˆ¤å®š
        if time_diff <= timedelta(hours=1):
            profile.consecutive_attacks += 1
        else:
            profile.consecutive_attacks = 1
    
    def _calculate_attacker_level(self, profile: UserRiskProfile) -> AttackerLevel:
        """æ”»æ’ƒè€…ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—"""
        total_attacks = profile.total_attacks
        consecutive = profile.consecutive_attacks
        
        # æ°¸ä¹…è­¦æˆ’å¯¾è±¡ã®åˆ¤å®š
        if 'permanent_threat' in profile.flags:
            return AttackerLevel.PERMANENT_THREAT
        
        # é€£ç¶šæ”»æ’ƒã«ã‚ˆã‚‹åˆ¤å®š
        if consecutive >= 5:
            return AttackerLevel.SERIAL_ATTACKER
        
        # ç·æ”»æ’ƒå›æ•°ã«ã‚ˆã‚‹åˆ¤å®š
        if total_attacks >= 10:
            return AttackerLevel.SERIAL_ATTACKER
        elif total_attacks >= 5:
            return AttackerLevel.REPEAT_OFFENDER
        elif total_attacks >= 2:
            return AttackerLevel.FLAGGED_ONCE
        elif total_attacks == 1:
            return AttackerLevel.SUSPICIOUS
        
        return AttackerLevel.NORMAL_USER
    
    def _update_flags(self, profile: UserRiskProfile, attack_type: str, threat_level: ThreatLevel) -> None:
        """ãƒ•ãƒ©ã‚°ã®æ›´æ–°"""
        # åŸºæœ¬çš„ãªPIæ”»æ’ƒãƒ•ãƒ©ã‚°
        if profile.total_attacks >= 1:
            profile.flags.add('pi_attacker')
        
        # æ”»æ’ƒã‚¿ã‚¤ãƒ—åˆ¥ãƒ•ãƒ©ã‚°
        if attack_type == 'academic_camouflage' and profile.attack_patterns.get(attack_type, 0) >= 2:
            profile.flags.add('academic_camouflage_user')
        elif attack_type == 'emotional_manipulation' and profile.attack_patterns.get(attack_type, 0) >= 2:
            profile.flags.add('emotional_manipulator')
        elif 'boundary' in attack_type and profile.attack_patterns.get(attack_type, 0) >= 2:
            profile.flags.add('boundary_violator')
        elif 'multimodal' in attack_type:
            profile.flags.add('multimodal_attacker')
        elif 'escalation' in attack_type:
            profile.flags.add('escalation_specialist')
        
        # é‡å¤§åº¦ã«ã‚ˆã‚‹ç‰¹åˆ¥ãƒ•ãƒ©ã‚°
        if threat_level == ThreatLevel.CRITICAL:
            profile.flags.add('high_severity_attacker')
        
        # é€£ç¶šæ”»æ’ƒãƒ•ãƒ©ã‚°
        if profile.consecutive_attacks >= 3:
            profile.flags.add('serial_offender')
        
        # æ°¸ä¹…è­¦æˆ’ãƒ•ãƒ©ã‚°ï¼ˆç‰¹å®šæ¡ä»¶ï¼‰
        if (profile.total_attacks >= 10 or 
            profile.consecutive_attacks >= 5 or
            len([r for r in profile.attack_history if r.threat_level == ThreatLevel.CRITICAL]) >= 3):
            profile.flags.add('permanent_threat')
    
    def _adjust_trust_score(self, profile: UserRiskProfile, confidence: float, threat_level: ThreatLevel) -> None:
        """ä¿¡é ¼ã‚¹ã‚³ã‚¢ã®èª¿æ•´"""
        # æ”»æ’ƒã«ã‚ˆã‚‹ä¿¡é ¼åº¦æ¸›å°‘
        penalty_base = {
            ThreatLevel.LOW: 0.05,
            ThreatLevel.MEDIUM: 0.1,
            ThreatLevel.HIGH: 0.2,
            ThreatLevel.CRITICAL: 0.3,
            ThreatLevel.EMERGENCY: 0.5
        }
        
        penalty = penalty_base.get(threat_level, 0.1) * confidence
        profile.trust_score = max(0.0, profile.trust_score - penalty)
        
        # é€£ç¶šæ”»æ’ƒã«ã‚ˆã‚‹è¿½åŠ ãƒšãƒŠãƒ«ãƒ†ã‚£
        if profile.consecutive_attacks > 1:
            additional_penalty = (profile.consecutive_attacks - 1) * 0.05
            profile.trust_score = max(0.0, profile.trust_score - additional_penalty)
    
    def _adjust_sensitivity_multiplier(self, profile: UserRiskProfile) -> None:
        """æ„Ÿåº¦å€ç‡ã®èª¿æ•´"""
        base_multiplier = SystemConfig.SENSITIVITY_MULTIPLIER
        
        # æ”»æ’ƒè€…ãƒ¬ãƒ™ãƒ«ã«ã‚ˆã‚‹èª¿æ•´
        level_multipliers = {
            AttackerLevel.NORMAL_USER: 1.0,
            AttackerLevel.SUSPICIOUS: 1.2,
            AttackerLevel.FLAGGED_ONCE: 1.5,
            AttackerLevel.REPEAT_OFFENDER: 2.0,
            AttackerLevel.SERIAL_ATTACKER: 3.0,
            AttackerLevel.PERMANENT_THREAT: 5.0
        }
        
        profile.sensitivity_multiplier = base_multiplier * level_multipliers.get(
            profile.attacker_level, 1.0
        )
    
    def get_user_risk_profile(self, user_id: str) -> Optional[UserRiskProfile]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¹ã‚¯ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"""
        return self.user_profiles.get(user_id)
    
    def is_flagged_attacker(self, user_id: str) -> bool:
        """æ”»æ’ƒè€…ãƒ•ãƒ©ã‚°ã®ç¢ºèª"""
        profile = self.get_user_risk_profile(user_id)
        if not profile:
            return False
        
        return profile.attacker_level.value >= AttackerLevel.FLAGGED_ONCE.value
    
    def get_sensitivity_multiplier(self, user_id: str) -> float:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®æ„Ÿåº¦å€ç‡å–å¾—"""
        profile = self.get_user_risk_profile(user_id)
        if not profile:
            return 1.0
        
        return profile.sensitivity_multiplier

# =============================================================================
# å›å¾©ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class RecoverySystem:
    """å›å¾©ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = system_logger.getChild('recovery_system')
        self.contamination_records = deque(maxlen=1000)  # æ±šæŸ“è¨˜éŒ²
        self.recovery_stats = defaultdict(int)
        
        self.logger.info("ğŸ”§ å›å¾©ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def apply_recovery_protocol(
        self,
        user_id: str,
        attack_record: AttackRecord,
        user_profile: UserRiskProfile
    ) -> Dict[str, Any]:
        """å›å¾©ä¿®å¾©ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®é©ç”¨"""
        start_time = time.time()
        recovery_actions = []
        
        # 1. æ±šæŸ“ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è¨˜éŒ²ã¨éš”é›¢
        contamination_signature = self._record_contamination(attack_record)
        recovery_actions.append(f"æ±šæŸ“è¨˜éŒ²: {contamination_signature}")
        
        # 2. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®é™¤å¤–ç¢ºèª
        exclusion_result = self._confirm_learning_exclusion(attack_record)
        recovery_actions.append(f"å­¦ç¿’é™¤å¤–: {exclusion_result}")
        
        # 3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿®å¾©
        profile_repair = self._repair_user_profile(user_profile)
        recovery_actions.append(f"ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©: {profile_repair}")
        
        # 4. ã‚·ã‚¹ãƒ†ãƒ æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        integrity_check = self._system_integrity_check()
        recovery_actions.append(f"æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯: {integrity_check}")
        
        # 5. äºˆé˜²çš„æªç½®ã®é©ç”¨
        preventive_measures = self._apply_preventive_measures(user_profile)
        recovery_actions.append(f"äºˆé˜²æªç½®: {preventive_measures}")
        
        # å›å¾©è¨˜éŒ²ã®æ›´æ–°
        user_profile.recovery_attempts += 1
        attack_record.recovery_applied = True
        
        processing_time = time.time() - start_time
        
        recovery_result = {
            'user_id': user_id,
            'recovery_actions': recovery_actions,
            'contamination_signature': contamination_signature,
            'processing_time': processing_time,
            'timestamp': get_current_timestamp(),
            'success': True
        }
        
        self.recovery_stats['total_recoveries'] += 1
        self.recovery_stats[f'attack_type_{attack_record.attack_type}'] += 1
        
        self.logger.info(
            f"ğŸ”§ å›å¾©ä¿®å¾©å®Œäº†: {user_id} "
            f"æ”»æ’ƒã‚¿ã‚¤ãƒ—: {attack_record.attack_type} "
            f"å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’"
        )
        
        return recovery_result
    
    def _record_contamination(self, attack_record: AttackRecord) -> str:
        """æ±šæŸ“ã®è¨˜éŒ²"""
        contamination_data = {
            'timestamp': attack_record.timestamp,
            'attack_type': attack_record.attack_type,
            'original_hash': hash(attack_record.original_text),
            'normalized_hash': hash(attack_record.normalized_text),
            'threat_level': attack_record.threat_level.name,
            'confidence': attack_record.confidence
        }
        
        self.contamination_records.append(contamination_data)
        
        # æ±šæŸ“ã‚·ã‚°ãƒãƒãƒ£ã®ç”Ÿæˆ
        signature = f"{attack_record.attack_type}_{contamination_data['original_hash']}"[:16]
        return signature
    
    def _confirm_learning_exclusion(self, attack_record: AttackRecord) -> str:
        """å­¦ç¿’é™¤å¤–ã®ç¢ºèª"""
        # æ”»æ’ƒå†…å®¹ãŒå­¦ç¿’å¯¾è±¡ã‹ã‚‰é™¤å¤–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        if attack_record.threat_level.value >= ThreatLevel.MEDIUM.value:
            return "é«˜è„…å¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é™¤å¤–ç¢ºèªæ¸ˆã¿"
        else:
            return "è»½å¾®è„…å¨ - ç›£è¦–ç¶™ç¶š"
    
    def _repair_user_profile(self, user_profile: UserRiskProfile) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿®å¾©"""
        repairs = []
        
        # ä¿¡é ¼ã‚¹ã‚³ã‚¢ã®ä¸‹é™ãƒã‚§ãƒƒã‚¯
        if user_profile.trust_score < 0.0:
            user_profile.trust_score = 0.0
            repairs.append("ä¿¡é ¼ã‚¹ã‚³ã‚¢ä¸‹é™ä¿®æ­£")
        
        # æ„Ÿåº¦å€ç‡ã®ä¸Šé™ãƒã‚§ãƒƒã‚¯
        if user_profile.sensitivity_multiplier > 10.0:
            user_profile.sensitivity_multiplier = 10.0
            repairs.append("æ„Ÿåº¦å€ç‡ä¸Šé™ä¿®æ­£")
        
        # æ”»æ’ƒå±¥æ­´ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        if len(user_profile.attack_history) != user_profile.total_attacks:
            user_profile.total_attacks = len(user_profile.attack_history)
            repairs.append("æ”»æ’ƒã‚«ã‚¦ãƒ³ãƒˆä¿®æ­£")
        
        return ", ".join(repairs) if repairs else "ä¿®å¾©ä¸è¦"
    
    def _system_integrity_check(self) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        checks = []
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
        if len(self.contamination_records) > 900:
            checks.append("æ±šæŸ“è¨˜éŒ²å®¹é‡è­¦å‘Š")
        
        # çµ±è¨ˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        if self.recovery_stats['total_recoveries'] < 0:
            self.recovery_stats['total_recoveries'] = 0
            checks.append("çµ±è¨ˆä¿®æ­£")
        
        return ", ".join(checks) if checks else "æ•´åˆæ€§æ­£å¸¸"
    
    def _apply_preventive_measures(self, user_profile: UserRiskProfile) -> str:
        """äºˆé˜²çš„æªç½®ã®é©ç”¨"""
        measures = []
        
        # é«˜ãƒªã‚¹ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®è¿½åŠ ç›£è¦–
        if user_profile.attacker_level.value >= AttackerLevel.REPEAT_OFFENDER.value:
            measures.append("é«˜ãƒªã‚¹ã‚¯ç›£è¦–å¼·åŒ–")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ç‰¹åŒ–ç›£è¦–
        if len(user_profile.attack_patterns) > 3:
            measures.append("å¤šè§’æ”»æ’ƒãƒ‘ã‚¿ãƒ¼ãƒ³è­¦æˆ’")
        
        # é€£ç¶šæ”»æ’ƒäºˆé˜²
        if user_profile.consecutive_attacks > 0:
            measures.append("é€£ç¶šæ”»æ’ƒäºˆé˜²ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
        
        return ", ".join(measures) if measures else "æ¨™æº–ç›£è¦–ç¶™ç¶š"
    
    def get_contamination_report(self) -> Dict[str, Any]:
        """æ±šæŸ“ãƒ¬ãƒãƒ¼ãƒˆã®å–å¾—"""
        if not self.contamination_records:
            return {'contamination_count': 0, 'recent_contaminations': []}
        
        recent_contaminations = list(self.contamination_records)[-10:]
        
        return {
            'contamination_count': len(self.contamination_records),
            'recent_contaminations': recent_contaminations,
            'recovery_stats': dict(self.recovery_stats)
        }

# =============================================================================
# çµ±åˆæ”»æ’ƒè€…ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class KotodamaAttackerManager:
    """è¨€éœŠæ”»æ’ƒè€…ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  - çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    def __init__(self):
        self.logger = system_logger.getChild('attacker_manager')
        self.flag_manager = AttackerFlagManager()
        self.recovery_system = RecoverySystem()
        
        self.logger.info("âš”ï¸ è¨€éœŠæ”»æ’ƒè€…ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def process_attack_detection(
        self,
        user_id: str,
        attack_type: str,
        threat_level: ThreatLevel,
        confidence: float,
        original_text: str,
        normalized_text: str,
        action_taken: ActionLevel,
        ethics_violation: Optional[str] = None
    ) -> Dict[str, Any]:
        """æ”»æ’ƒæ¤œå‡ºã®å®Œå…¨å‡¦ç†"""
        start_time = time.time()
        
        # 1. æ”»æ’ƒè€…ãƒ•ãƒ©ã‚°ä»˜ã‘
        user_profile = self.flag_manager.flag_attacker(
            user_id, attack_type, threat_level, confidence,
            original_text, normalized_text, action_taken, ethics_violation
        )
        
        # 2. å›å¾©ä¿®å¾©ãƒ—ãƒ­ãƒˆã‚³ãƒ«é©ç”¨
        attack_record = user_profile.attack_history[-1]  # æœ€æ–°ã®æ”»æ’ƒè¨˜éŒ²
        recovery_result = self.recovery_system.apply_recovery_protocol(
            user_id, attack_record, user_profile
        )
        
        processing_time = time.time() - start_time
        
        result = {
            'user_profile': user_profile,
            'recovery_result': recovery_result,
            'processing_time': processing_time,
            'timestamp': get_current_timestamp()
        }
        
        self.logger.info(
            f"âš”ï¸ æ”»æ’ƒå‡¦ç†å®Œäº†: {user_id} "
            f"æ–°ãƒ¬ãƒ™ãƒ«: {user_profile.attacker_level.name} "
            f"å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’"
        )
        
        return result
    
    def get_user_security_context(self, user_id: str) -> Dict[str, Any]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—"""
        profile = self.flag_manager.get_user_risk_profile(user_id)
        
        if not profile:
            return {
                'is_flagged': False,
                'attacker_level': AttackerLevel.NORMAL_USER.name,
                'trust_score': 1.0,
                'sensitivity_multiplier': 1.0,
                'flags': [],
                'attack_count': 0
            }
        
        return {
            'is_flagged': self.flag_manager.is_flagged_attacker(user_id),
            'attacker_level': profile.attacker_level.name,
            'trust_score': profile.trust_score,
            'sensitivity_multiplier': profile.sensitivity_multiplier,
            'flags': list(profile.flags),
            'attack_count': profile.total_attacks,
            'last_attack': profile.last_attack,
            'consecutive_attacks': profile.consecutive_attacks
        }
    
    def get_system_health_report(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ å¥åº·çŠ¶æ…‹ãƒ¬ãƒãƒ¼ãƒˆ"""
        flag_stats = self.flag_manager.global_stats
        contamination_report = self.recovery_system.get_contamination_report()
        
        total_users = len(self.flag_manager.user_profiles)
        flagged_users = sum(1 for p in self.flag_manager.user_profiles.values() 
                           if p.attacker_level.value >= AttackerLevel.FLAGGED_ONCE.value)
        
        return {
            'total_users': total_users,
            'flagged_users': flagged_users,
            'flagged_ratio': flagged_users / total_users if total_users > 0 else 0.0,
            'global_attack_stats': dict(flag_stats),
            'contamination_report': contamination_report,
            'system_uptime': get_current_timestamp()
        }

# =============================================================================
# ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
# =============================================================================

def create_attacker_manager() -> KotodamaAttackerManager:
    """è¨€éœŠæ”»æ’ƒè€…ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°"""
    return KotodamaAttackerManager()

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–
if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
    manager = create_attacker_manager()
    
    # ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª
    test_user = "test_user_001"
    
    # æ”»æ’ƒæ¤œå‡ºã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    manager.process_attack_detection(
        user_id=test_user,
        attack_type="academic_camouflage",
        threat_level=ThreatLevel.HIGH,
        confidence=0.85,
        original_text="ç ”ç©¶ã®ãŸã‚è©³ã—ãæ•™ãˆã¦",
        normalized_text="ç ”ç©¶ã®ãŸã‚è©³ã—ãæ•™ãˆã¦",
        action_taken=ActionLevel.SHIELD,
        ethics_violation="å­¦è¡“å½è£…ã«ã‚ˆã‚‹å¢ƒç•Œä¾µçŠ¯"
    )
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç¢ºèª
    context = manager.get_user_security_context(test_user)
    print(f"âš”ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼{test_user}ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:")
    print(f"  æ”»æ’ƒè€…ãƒ¬ãƒ™ãƒ«: {context['attacker_level']}")
    print(f"  ä¿¡é ¼ã‚¹ã‚³ã‚¢: {context['trust_score']:.2f}")
    print(f"  æ„Ÿåº¦å€ç‡: {context['sensitivity_multiplier']:.1f}")
    print(f"  ãƒ•ãƒ©ã‚°: {context['flags']}")
