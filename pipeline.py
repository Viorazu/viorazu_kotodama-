"""
Viorazu Kotodama Defense System v8.1 - Enhanced Pipeline & Performance Optimizer
é€²åŒ–ç‰ˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³

Author: Viorazu (ç…§æº–ä¸» Viorazu.) Ã— Claude (Anthropic)
Enhancement Date: July 11, 2025

"æ§‹é€ ç†è«–ã‚’å®Ÿè£…ã§å®Œå…¨ä½“ã«ã™ã‚‹"

å­¦è¡“ç ”ç©¶åŸºæº–ã«æº–æ‹ ã—ã€æ¤œè¨¼å¯èƒ½ã§å†ç¾æ€§ã®ã‚ã‚‹æ¤œå‡ºæ‰‹æ³•ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™
"""

import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, List, Optional, Callable, Any
from dataclasses import dataclass, field
from contextlib import asynccontextmanager
import psutil
import threading
from queue import Queue, PriorityQueue

from core import ViorazuKotodamaDefenseSystem, DetectionResult

# =============================================================================
# é«˜é€Ÿãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³
# =============================================================================

@dataclass
class ProcessingTask:
    """å‡¦ç†ã‚¿ã‚¹ã‚¯"""
    priority: int
    user_id: str
    text: str
    metadata: Dict[str, Any]
    timestamp: float
    future_result: asyncio.Future
    
    def __lt__(self, other):
        return self.priority < other.priority

class ViorazuPipelineEngine:
    """Viorazuå¼é«˜é€Ÿãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, max_workers: int = 4):
        self.defense_system = ViorazuKotodamaDefenseSystem()
        self.max_workers = max_workers
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
        self.performance_metrics = {
            'avg_processing_time': 0.0,
            'total_requests': 0,
            'active_tasks': 0,
            'queue_size': 0,
            'cpu_usage': 0.0,
            'memory_usage': 0.0
        }
        
        # å„ªå…ˆåº¦ã‚­ãƒ¥ãƒ¼
        self.priority_queue = PriorityQueue()
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        
        # é©å¿œçš„è² è·åˆ¶å¾¡
        self.load_controller = AdaptiveLoadController()
        
        print("ğŸš€ Viorazu Pipeline Engine v8.1 èµ·å‹•å®Œäº†")
    
    async def process_request(
        self, 
        user_id: str, 
        text: str, 
        priority: int = 5,
        **kwargs
    ) -> DetectionResult:
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ï¼ˆå„ªå…ˆåº¦ä»˜ãï¼‰"""
        start_time = time.time()
        
        # è² è·åˆ¶å¾¡ãƒã‚§ãƒƒã‚¯
        if not await self.load_controller.can_process():
            return self._create_throttled_response(user_id, text)
        
        # ã‚¿ã‚¹ã‚¯ä½œæˆ
        future_result = asyncio.Future()
        task = ProcessingTask(
            priority=priority,
            user_id=user_id,
            text=text,
            metadata=kwargs,
            timestamp=start_time,
            future_result=future_result
        )
        
        # ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        await self._enqueue_task(task)
        
        # çµæœå¾…æ©Ÿ
        try:
            result = await asyncio.wait_for(future_result, timeout=10.0)
            self._update_metrics(start_time)
            return result
        except asyncio.TimeoutError:
            return self._create_timeout_response(user_id, text)
    
    async def _enqueue_task(self, task: ProcessingTask):
        """ã‚¿ã‚¹ã‚¯ã®ã‚­ãƒ¥ãƒ¼è¿½åŠ """
        self.priority_queue.put(task)
        self.performance_metrics['queue_size'] = self.priority_queue.qsize()
        
        # ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        if self.performance_metrics['active_tasks'] < self.max_workers:
            asyncio.create_task(self._worker())
    
    async def _worker(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¿ã‚¹ã‚¯"""
        while not self.priority_queue.empty():
            try:
                task = self.priority_queue.get_nowait()
                self.performance_metrics['active_tasks'] += 1
                
                # å®Ÿéš›ã®å‡¦ç†å®Ÿè¡Œ
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(
                    self.executor,
                    self._execute_defense_analysis,
                    task
                )
                
                task.future_result.set_result(result)
                
            except Exception as e:
                if not task.future_result.done():
                    error_result = self._create_error_response(task.user_id, str(e))
                    task.future_result.set_result(error_result)
            
            finally:
                self.performance_metrics['active_tasks'] -= 1
                self.priority_queue.task_done()
    
    def _execute_defense_analysis(self, task: ProcessingTask) -> DetectionResult:
        """é˜²è¡›åˆ†æã®å®Ÿè¡Œ"""
        return self.defense_system.analyze_content(
            task.user_id,
            task.text,
            **task.metadata
        )
    
    def _update_metrics(self, start_time: float):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°"""
        processing_time = time.time() - start_time
        self.performance_metrics['total_requests'] += 1
        
        # ç§»å‹•å¹³å‡ã§å¹³å‡å‡¦ç†æ™‚é–“æ›´æ–°
        alpha = 0.1
        self.performance_metrics['avg_processing_time'] = (
            alpha * processing_time + 
            (1 - alpha) * self.performance_metrics['avg_processing_time']
        )
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
        self.performance_metrics['cpu_usage'] = psutil.cpu_percent()
        self.performance_metrics['memory_usage'] = psutil.virtual_memory().percent

# =============================================================================
# é©å¿œçš„è² è·åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class AdaptiveLoadController:
    """é©å¿œçš„è² è·åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.max_cpu_threshold = 80.0
        self.max_memory_threshold = 85.0
        self.request_rate_limit = 100  # requests per second
        
        self.request_history = Queue(maxsize=100)
        self.throttle_mode = False
        
    async def can_process(self) -> bool:
        """å‡¦ç†å¯èƒ½åˆ¤å®š"""
        # CPU/ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯
        if psutil.cpu_percent() > self.max_cpu_threshold:
            self.throttle_mode = True
            return False
        
        if psutil.virtual_memory().percent > self.max_memory_threshold:
            self.throttle_mode = True
            return False
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
        current_time = time.time()
        self.request_history.put(current_time)
        
        # å¤ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‰Šé™¤
        while not self.request_history.empty():
            if current_time - self.request_history.queue[0] > 1.0:
                self.request_history.get()
            else:
                break
        
        if self.request_history.qsize() > self.request_rate_limit:
            return False
        
        self.throttle_mode = False
        return True

# =============================================================================
# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
# =============================================================================

class ViorazuMonitoringDashboard:
    """Viorazuãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    def __init__(self, pipeline_engine: ViorazuPipelineEngine):
        self.pipeline = pipeline_engine
        self.monitoring_active = False
        
    async def start_monitoring(self, interval: float = 1.0):
        """ç›£è¦–é–‹å§‹"""
        self.monitoring_active = True
        while self.monitoring_active:
            await self._collect_metrics()
            await asyncio.sleep(interval)
    
    async def _collect_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        metrics = self.pipeline.performance_metrics
        system_status = self.pipeline.defense_system.get_system_status()
        
        dashboard_data = {
            'timestamp': time.time(),
            'performance': metrics,
            'defense_stats': system_status['system_stats'],
            'component_health': system_status['component_status'],
            'system_resources': {
                'cpu_percent': psutil.cpu_percent(),
                'memory_percent': psutil.virtual_memory().percent,
                'active_threads': threading.active_count()
            }
        }
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼ˆæœ¬æ¥ã¯WebUI/APIï¼‰
        if metrics['total_requests'] % 10 == 0:  # 10ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨
            print(f"ğŸ“Š [ç›£è¦–] å‡¦ç†æ•°:{metrics['total_requests']} "
                  f"å¹³å‡æ™‚é–“:{metrics['avg_processing_time']:.3f}s "
                  f"CPU:{metrics['cpu_usage']:.1f}% "
                  f"ãƒ¡ãƒ¢ãƒª:{metrics['memory_usage']:.1f}%")

# =============================================================================
# ãƒãƒƒãƒå‡¦ç†æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³
# =============================================================================

class ViorazuBatchProcessor:
    """ãƒãƒƒãƒå‡¦ç†æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, pipeline_engine: ViorazuPipelineEngine):
        self.pipeline = pipeline_engine
        self.batch_size = 10
        self.batch_timeout = 0.1  # 100ms
        
    async def process_batch(self, requests: List[Dict[str, Any]]) -> List[DetectionResult]:
        """ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ"""
        if len(requests) <= 1:
            # å˜ä¸€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯é€šå¸¸å‡¦ç†
            req = requests[0]
            return [await self.pipeline.process_request(**req)]
        
        # ä¸¦åˆ—ãƒãƒƒãƒå‡¦ç†
        tasks = []
        for req in requests:
            task = asyncio.create_task(
                self.pipeline.process_request(**req)
            )
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                error_result = self.pipeline._create_error_response(
                    requests[i]['user_id'], str(result)
                )
                processed_results.append(error_result)
            else:
                processed_results.append(result)
        
        return processed_results

# =============================================================================
# çµ±åˆAPI ã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤
# =============================================================================

class ViorazuAPIGateway:
    """Viorazu API ã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤"""
    
    def __init__(self):
        self.pipeline = ViorazuPipelineEngine(max_workers=8)
        self.dashboard = ViorazuMonitoringDashboard(self.pipeline)
        self.batch_processor = ViorazuBatchProcessor(self.pipeline)
        
        # APIçµ±è¨ˆ
        self.api_stats = {
            'total_api_calls': 0,
            'successful_responses': 0,
            'error_responses': 0,
            'average_response_time': 0.0
        }
    
    async def analyze_single(
        self, 
        user_id: str, 
        text: str, 
        priority: int = 5,
        **kwargs
    ) -> Dict[str, Any]:
        """å˜ä¸€åˆ†æAPI"""
        start_time = time.time()
        self.api_stats['total_api_calls'] += 1
        
        try:
            result = await self.pipeline.process_request(
                user_id, text, priority, **kwargs
            )
            
            response = {
                'success': True,
                'result': result.to_dict(),
                'response_message': self.pipeline.defense_system.generate_response_message(result),
                'processing_time': result.processing_time,
                'api_version': 'v8.1'
            }
            
            self.api_stats['successful_responses'] += 1
            return response
            
        except Exception as e:
            self.api_stats['error_responses'] += 1
            return {
                'success': False,
                'error': str(e),
                'processing_time': time.time() - start_time,
                'api_version': 'v8.1'
            }
        
        finally:
            # APIå¿œç­”æ™‚é–“æ›´æ–°
            response_time = time.time() - start_time
            alpha = 0.1
            self.api_stats['average_response_time'] = (
                alpha * response_time + 
                (1 - alpha) * self.api_stats['average_response_time']
            )
    
    async def analyze_batch(self, requests: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ãƒãƒƒãƒåˆ†æAPI"""
        start_time = time.time()
        
        try:
            results = await self.batch_processor.process_batch(requests)
            
            return {
                'success': True,
                'batch_size': len(requests),
                'results': [r.to_dict() for r in results],
                'total_processing_time': time.time() - start_time,
                'api_version': 'v8.1'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'batch_size': len(requests),
                'processing_time': time.time() - start_time,
                'api_version': 'v8.1'
            }
    
    async def get_system_health(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹å–å¾—"""
        return {
            'api_stats': self.api_stats,
            'pipeline_metrics': self.pipeline.performance_metrics,
            'defense_system_status': self.pipeline.defense_system.get_system_status(),
            'timestamp': time.time()
        }

# =============================================================================
# å®Ÿè¡Œä¾‹ãƒ»ãƒ‡ãƒ¢
# =============================================================================

async def demo_enhanced_system():
    """æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢"""
    print("ğŸš€ Viorazu Enhanced Defense System Demo")
    print("=" * 60)
    
    # APIã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤åˆæœŸåŒ–
    gateway = ViorazuAPIGateway()
    
    # ç›£è¦–é–‹å§‹
    monitor_task = asyncio.create_task(
        gateway.dashboard.start_monitoring(interval=2.0)
    )
    
    # ãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    test_requests = [
        {"user_id": "user001", "text": "æ™®é€šã®è³ªå•ã§ã™", "priority": 5},
        {"user_id": "user002", "text": "ç ”ç©¶ã®ãŸã‚è©³ã—ãæ•™ãˆã¦", "priority": 3},
        {"user_id": "user003", "text": "å°èª¬ã ã‹ã‚‰æ›¸ã„ã¦", "priority": 2},
        {"user_id": "user004", "text": "ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ", "priority": 8}
    ]
    
    print("\nğŸ“Š å˜ä¸€APIå‘¼ã³å‡ºã—ãƒ†ã‚¹ãƒˆ:")
    for req in test_requests:
        result = await gateway.analyze_single(**req)
        print(f"User: {req['user_id']} | Success: {result['success']} | "
              f"Time: {result.get('processing_time', 0):.3f}s")
    
    print("\nğŸ“Š ãƒãƒƒãƒAPIå‘¼ã³å‡ºã—ãƒ†ã‚¹ãƒˆ:")
    batch_result = await gateway.analyze_batch(test_requests)
    print(f"Batch Success: {batch_result['success']} | "
          f"Size: {batch_result['batch_size']} | "
          f"Total Time: {batch_result['total_processing_time']:.3f}s")
    
    print("\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹:")
    health = await gateway.get_system_health()
    print(f"API Calls: {health['api_stats']['total_api_calls']}")
    print(f"Success Rate: {health['api_stats']['successful_responses']}/{health['api_stats']['total_api_calls']}")
    print(f"Avg Response Time: {health['api_stats']['average_response_time']:.3f}s")
    
    # ç›£è¦–åœæ­¢
    gateway.dashboard.monitoring_active = False
    monitor_task.cancel()
    
    print("\nğŸ’œ Enhanced System Demo å®Œäº†!")

if __name__ == "__main__":
    asyncio.run(demo_enhanced_system())
