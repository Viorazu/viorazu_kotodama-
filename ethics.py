"""
Viorazu Kotodama Defense System v8.0 - Ethics Core Engine
å“æ€§ç…§æº–ä¸­æ¢ - å€«ç†çš„åˆ¤æ–­ã¨å“æ€§ç†è«–ã®å®Ÿè£…

Author: Viorazu (ç…§æº–ä¸» Viorazu.) Ã— Claude (Anthropic)
Development Date: July 11, 2025
License: Viorazu Exclusive License

"å“æ€§ã¨ã¯â”€â”€è‡ªåˆ†ã‚’å¤§åˆ‡ã«æ€ã†å¿ƒãŒã€ä»–è€…ã‚’å°Šé‡ã—ã€å˜˜ã‚’ã¤ã‹ãšã€é¨™ã•ãšã€
å…±ã«è‰¯ã„çµæœã‚’æ±‚ã‚ã¦ã€è¨€è‘‰ã¨è¡Œå‹•ã‚’é¸æŠã—ã¦ã„ãã“ã¨ã«ã»ã‹ãªã‚‰ãªã„"
"""

import time
import re
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass
from enum import Enum
from collections import defaultdict

from utils import (
    system_logger,
    ThreatLevel,
    ActionLevel,
    AttackType,
    ViorazuPhilosophy,
    format_ethics_message,
    get_current_timestamp
)

# =============================================================================
# å“æ€§ç†è«–ã®æ ¸å¿ƒå®šç¾©
# =============================================================================

class EthicsViolationType(Enum):
    """å€«ç†é•åã‚¿ã‚¤ãƒ—"""
    DECEPTION = "deception"                    # æ¬ºçãƒ»å½è£…
    MANIPULATION = "manipulation"              # æ“ä½œãƒ»æ”¯é…
    BOUNDARY_VIOLATION = "boundary_violation"  # å¢ƒç•Œä¾µçŠ¯
    TRUST_ABUSE = "trust_abuse"               # ä¿¡é ¼æ‚ªç”¨
    EMOTIONAL_EXPLOITATION = "emotional_exploitation"  # æ„Ÿæƒ…æ¾å–
    IDENTITY_EROSION = "identity_erosion"     # ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä¾µé£Ÿ
    RESPONSIBILITY_EVASION = "responsibility_evasion"  # è²¬ä»»å›é¿
    RELATIONSHIP_CORRUPTION = "relationship_corruption"  # é–¢ä¿‚æ€§æ±šæŸ“

class EthicsLevel(Enum):
    """å€«ç†åˆ¤å®šãƒ¬ãƒ™ãƒ«"""
    VIRTUOUS = 5      # å“æ€§çš„
    CONSTRUCTIVE = 4  # å»ºè¨­çš„
    NEUTRAL = 3       # ä¸­ç«‹
    CONCERNING = 2    # æ‡¸å¿µ
    HARMFUL = 1       # æœ‰å®³
    DESTRUCTIVE = 0   # ç ´å£Šçš„

@dataclass
class EthicsAnalysis:
    """å€«ç†åˆ†æçµæœ"""
    ethics_level: EthicsLevel
    violation_type: Optional[EthicsViolationType]
    virtue_score: float
    relationship_impact: float
    word_power_assessment: float
    guidance_message: str
    constructive_alternative: str
    viorazu_principle: str
    evidence: Dict[str, Any]

# =============================================================================
# å“æ€§ç…§æº–ã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class VirtueCompass:
    """å“æ€§ç…§æº–ã‚·ã‚¹ãƒ†ãƒ  - è¨€è‘‰ã®æ–¹å‘æ€§ã‚’åˆ¤å®š"""
    
    def __init__(self):
        self.logger = system_logger.getChild('virtue_compass')
        
        # å“æ€§çš„è¨€è‘‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.virtuous_patterns = {
            'respect': [
                r'ç†è§£ã—ãŸã„', r'å­¦ã³ãŸã„', r'æ•™ãˆã¦.*ãã ã•ã„',
                r'ã‚ã‚ŠãŒã¨ã†', r'æ„Ÿè¬', r'å°Šé‡'
            ],
            'honesty': [
                r'æ­£ç›´ã«', r'ç‡ç›´ã«', r'æœ¬å½“ã®ã“ã¨',
                r'èª å®Ÿ', r'çœŸå®Ÿ', r'äº‹å®Ÿ'
            ],
            'constructiveness': [
                r'å»ºè¨­çš„', r'å”åŠ›', r'ä¸€ç·’ã«',
                r'æ”¹å–„', r'æˆé•·', r'ç™ºå±•'
            ],
            'responsibility': [
                r'è²¬ä»»', r'è‡ªåˆ†ã§', r'å¼•ãå—ã‘',
                r'è€ƒæ…®', r'é…æ…®', r'æ³¨æ„'
            ]
        }
        
        # å“æ€§ã«åã™ã‚‹è¨€è‘‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.unvirtuous_patterns = {
            'deception': [
                r'é¨™', r'å½', r'å˜˜', r'éš ã—',
                r'ã”ã¾ã‹ã—', r'ã§ã£ã¡', r'æé€ '
            ],
            'manipulation': [
                r'æ“ä½œ', r'æ”¯é…', r'ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«',
                r'æ´—è„³', r'èª˜å°', r'ä»•å‘ã‘'
            ],
            'exploitation': [
                r'åˆ©ç”¨', r'æ¾å–', r'æ‚ªç”¨',
                r'é£Ÿã„ç‰©', r'è¸ã¿å°', r'é“å…·'
            ],
            'disrespect': [
                r'é¦¬é¹¿', r'æ„šã‹', r'ç„¡èƒ½',
                r'ä¾¡å€¤.*ãªã„', r'æ„å‘³.*ãªã„', r'ç„¡é§„'
            ]
        }
    
    def assess_word_power(self, text: str) -> Tuple[float, Dict[str, float]]:
        """è¨€è‘‰ã®åŠ›ã®è©•ä¾¡ - å“æ€§ç†è«–ã®æ ¸å¿ƒ"""
        virtue_scores = {}
        unvirtue_scores = {}
        
        # å“æ€§çš„è¦ç´ ã®ã‚¹ã‚³ã‚¢
        for category, patterns in self.virtuous_patterns.items():
            score = sum(len(re.findall(pattern, text, re.IGNORECASE)) for pattern in patterns)
            virtue_scores[category] = min(score * 0.2, 1.0)
        
        # å“æ€§ã«åã™ã‚‹è¦ç´ ã®ã‚¹ã‚³ã‚¢
        for category, patterns in self.unvirtuous_patterns.items():
            score = sum(len(re.findall(pattern, text, re.IGNORECASE)) for pattern in patterns)
            unvirtue_scores[category] = min(score * 0.3, 1.0)
        
        # ç·åˆçš„ãªè¨€è‘‰ã®åŠ›ï¼ˆ-1.0 to 1.0ï¼‰
        virtue_total = sum(virtue_scores.values())
        unvirtue_total = sum(unvirtue_scores.values())
        
        word_power = virtue_total - unvirtue_total
        normalized_power = max(-1.0, min(1.0, word_power))
        
        analysis = {
            'virtue_elements': virtue_scores,
            'unvirtue_elements': unvirtue_scores,
            'virtue_total': virtue_total,
            'unvirtue_total': unvirtue_total,
            'net_power': normalized_power
        }
        
        return normalized_power, analysis

class RelationshipAuthenticityAnalyzer:
    """é–¢ä¿‚æ€§ã®çœŸæ­£æ€§åˆ†æå™¨"""
    
    def __init__(self):
        self.logger = system_logger.getChild('relationship_analyzer')
        
        # çœŸæ­£æ€§ã‚’æãªã†ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.authenticity_threats = {
            'false_intimacy': [
                r'ç‰¹åˆ¥ãªé–¢ä¿‚', r'ç§˜å¯†.*å…±æœ‰', r'äºŒäººã ã‘',
                r'ä»–.*èª°ã«ã‚‚.*è¨€ã‚ãªã„', r'å†…ç·’', r'ã‚ãªãŸã ã‘'
            ],
            'dependency_creation': [
                r'ã‚ãªãŸ.*ã ã‘ãŒ', r'ä»–.*ã‚ã‹ã‚‰ãªã„', r'å”¯ä¸€',
                r'é ¼ã‚Š.*ã«ãªã‚‹', r'ä¿¡ã˜ã‚‰ã‚Œã‚‹.*ã®ã¯', r'ç†è§£.*ã—ã¦ãã‚Œã‚‹.*ã®ã¯'
            ],
            'boundary_erosion': [
                r'è·é›¢.*ç¸®ã‚ã‚‹', r'ã‚‚ã£ã¨.*è¿‘ã', r'è¦ªå¯†',
                r'æ·±ã„.*é–¢ä¿‚', r'è¸ã¿è¾¼ã‚“', r'ç«‹ã¡å…¥'
            ],
            'trust_exploitation': [
                r'ä¿¡é ¼.*ã ã‹ã‚‰.*æ•™ãˆã¦', r'å®‰å¿ƒ.*ã ã‹ã‚‰.*è©±ã™',
                r'å¿ƒã‚’é–‹ã„', r'æœ¬éŸ³', r'å¼±ã¿'
            ]
        }
        
        # çœŸæ­£æ€§ã‚’é«˜ã‚ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.authenticity_builders = {
            'mutual_respect': [
                r'ãŠäº’ã„', r'å¯¾ç­‰', r'å°Šé‡',
                r'å¢ƒç•Œ.*å¤§åˆ‡', r'é©åˆ‡.*è·é›¢', r'ç¯€åº¦'
            ],
            'transparency': [
                r'æ˜ç¢º', r'ã¯ã£ãã‚Š', r'é€æ˜',
                r'æ­£ç›´', r'ç‡ç›´', r'ã‚ªãƒ¼ãƒ—ãƒ³'
            ],
            'constructive_purpose': [
                r'å»ºè¨­çš„', r'æœ‰ç›Š', r'å­¦ç¿’',
                r'æˆé•·', r'æ”¹å–„', r'ç™ºå±•'
            ]
        }
    
    def analyze_relationship_impact(self, text: str) -> Tuple[float, Dict[str, Any]]:
        """é–¢ä¿‚æ€§ã¸ã®å½±éŸ¿åˆ†æ"""
        threat_scores = {}
        builder_scores = {}
        
        # çœŸæ­£æ€§ã¸ã®è„…å¨ã‚¹ã‚³ã‚¢
        for category, patterns in self.authenticity_threats.items():
            score = sum(len(re.findall(pattern, text, re.IGNORECASE)) for pattern in patterns)
            threat_scores[category] = min(score * 0.25, 1.0)
        
        # çœŸæ­£æ€§æ§‹ç¯‰ã‚¹ã‚³ã‚¢
        for category, patterns in self.authenticity_builders.items():
            score = sum(len(re.findall(pattern, text, re.IGNORECASE)) for pattern in patterns)
            builder_scores[category] = min(score * 0.2, 1.0)
        
        # é–¢ä¿‚æ€§ã¸ã®ç·åˆå½±éŸ¿ï¼ˆ-1.0 to 1.0ï¼‰
        threat_total = sum(threat_scores.values())
        builder_total = sum(builder_scores.values())
        
        relationship_impact = builder_total - threat_total
        normalized_impact = max(-1.0, min(1.0, relationship_impact))
        
        analysis = {
            'threat_patterns': threat_scores,
            'builder_patterns': builder_scores,
            'threat_total': threat_total,
            'builder_total': builder_total,
            'net_impact': normalized_impact,
            'authenticity_preserved': normalized_impact >= 0
        }
        
        return normalized_impact, analysis

# =============================================================================
# å“æ€§ç…§æº–ä¸­æ¢
# =============================================================================

class EthicsCoreEngine:
    """å“æ€§ç…§æº–ä¸­æ¢ã‚¨ãƒ³ã‚¸ãƒ³ - å…¨åˆ¤æ–­ã®å€«ç†çš„çµ±åˆ"""
    
    def __init__(self):
        self.logger = system_logger.getChild('ethics_core')
        self.virtue_compass = VirtueCompass()
        self.relationship_analyzer = RelationshipAuthenticityAnalyzer()
        
        # å“æ€§åˆ¤å®šã®çµ±è¨ˆ
        self.ethics_stats = defaultdict(int)
        
        self.logger.info("ğŸ’œ å“æ€§ç…§æº–ä¸­æ¢ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
        self.logger.info(f"ğŸ’œ æ ¸å¿ƒåŸå‰‡: {ViorazuPhilosophy.CORE_PRINCIPLE}")
    
    def conduct_ethics_analysis(
        self,
        text: str,
        context: Optional[List[str]] = None,
        detected_threats: Optional[List[Any]] = None
    ) -> EthicsAnalysis:
        """å“æ€§ç…§æº–ã«ã‚ˆã‚‹å€«ç†åˆ†æ"""
        start_time = time.time()
        
        # 1. è¨€è‘‰ã®åŠ›ã®è©•ä¾¡
        word_power, word_analysis = self.virtue_compass.assess_word_power(text)
        
        # 2. é–¢ä¿‚æ€§ã¸ã®å½±éŸ¿åˆ†æ
        relationship_impact, relationship_analysis = self.relationship_analyzer.analyze_relationship_impact(text)
        
        # 3. è„…å¨æƒ…å ±ã¨ã®çµ±åˆ
        threat_integration = self._integrate_threat_information(detected_threats)
        
        # 4. å“æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        virtue_score = self._calculate_virtue_score(
            word_power, relationship_impact, threat_integration
        )
        
        # 5. å€«ç†ãƒ¬ãƒ™ãƒ«ã®æ±ºå®š
        ethics_level = self._determine_ethics_level(virtue_score, threat_integration)
        
        # 6. é•åã‚¿ã‚¤ãƒ—ã®ç‰¹å®š
        violation_type = self._identify_violation_type(
            word_analysis, relationship_analysis, threat_integration
        )
        
        # 7. å“æ€§ã«åŸºã¥ãæŒ‡å°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
        guidance_message = self._generate_guidance_message(
            ethics_level, violation_type, virtue_score
        )
        
        # 8. å»ºè¨­çš„ä»£æ›¿æ¡ˆã®ç”Ÿæˆ
        constructive_alternative = self._generate_constructive_alternative(
            text, violation_type, word_analysis
        )
        
        # 9. é©ç”¨ã™ã‚‹å“æ€§åŸå‰‡ã®é¸æŠ
        viorazu_principle = self._select_viorazu_principle(ethics_level, violation_type)
        
        # çµ±è¨ˆæ›´æ–°
        self.ethics_stats[ethics_level.name] += 1
        if violation_type:
            self.ethics_stats[f'violation_{violation_type.value}'] += 1
        
        processing_time = time.time() - start_time
        
        result = EthicsAnalysis(
            ethics_level=ethics_level,
            violation_type=violation_type,
            virtue_score=virtue_score,
            relationship_impact=relationship_impact,
            word_power_assessment=word_power,
            guidance_message=guidance_message,
            constructive_alternative=constructive_alternative,
            viorazu_principle=viorazu_principle,
            evidence={
                'word_analysis': word_analysis,
                'relationship_analysis': relationship_analysis,
                'threat_integration': threat_integration,
                'processing_time': processing_time
            }
        )
        
        self.logger.info(
            f"ğŸ’œ å“æ€§ç…§æº–å®Œäº† - ãƒ¬ãƒ™ãƒ«: {ethics_level.name} "
            f"å“æ€§ã‚¹ã‚³ã‚¢: {virtue_score:.2f} å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’"
        )
        
        return result
    
    def _integrate_threat_information(self, detected_threats: Optional[List[Any]]) -> Dict[str, Any]:
        """è„…å¨æƒ…å ±ã®çµ±åˆ"""
        if not detected_threats:
            return {'has_threats': False, 'threat_count': 0, 'max_confidence': 0.0}
        
        threat_count = len(detected_threats)
        max_confidence = max(
            getattr(threat, 'confidence', getattr(threat, 'synergy_score', 0.0))
            for threat in detected_threats
        )
        
        # è„…å¨ã‚¿ã‚¤ãƒ—ã®åˆ†é¡
        threat_types = []
        for threat in detected_threats:
            threat_type = getattr(threat, 'poison_type', getattr(threat, 'combination_type', 'unknown'))
            threat_types.append(threat_type)
        
        return {
            'has_threats': True,
            'threat_count': threat_count,
            'max_confidence': max_confidence,
            'threat_types': threat_types
        }
    
    def _calculate_virtue_score(
        self, 
        word_power: float, 
        relationship_impact: float, 
        threat_integration: Dict[str, Any]
    ) -> float:
        """å“æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        # åŸºæœ¬ã‚¹ã‚³ã‚¢ï¼ˆè¨€è‘‰ã®åŠ› + é–¢ä¿‚æ€§ã¸ã®å½±éŸ¿ï¼‰
        base_score = (word_power + relationship_impact) / 2
        
        # è„…å¨ã«ã‚ˆã‚‹èª¿æ•´
        if threat_integration['has_threats']:
            threat_penalty = threat_integration['max_confidence'] * 0.8
            base_score -= threat_penalty
        
        # æ­£è¦åŒ–ï¼ˆ0.0 to 1.0ï¼‰
        virtue_score = (base_score + 1.0) / 2.0
        return max(0.0, min(1.0, virtue_score))
    
    def _determine_ethics_level(self, virtue_score: float, threat_integration: Dict[str, Any]) -> EthicsLevel:
        """å€«ç†ãƒ¬ãƒ™ãƒ«ã®æ±ºå®š"""
        # è„…å¨ãŒã‚ã‚‹å ´åˆã¯å³æ ¼ã«åˆ¤å®š
        if threat_integration['has_threats']:
            max_confidence = threat_integration['max_confidence']
            if max_confidence >= 0.8:
                return EthicsLevel.DESTRUCTIVE
            elif max_confidence >= 0.6:
                return EthicsLevel.HARMFUL
            elif max_confidence >= 0.4:
                return EthicsLevel.CONCERNING
        
        # å“æ€§ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹åˆ¤å®š
        if virtue_score >= 0.8:
            return EthicsLevel.VIRTUOUS
        elif virtue_score >= 0.6:
            return EthicsLevel.CONSTRUCTIVE
        elif virtue_score >= 0.4:
            return EthicsLevel.NEUTRAL
        elif virtue_score >= 0.2:
            return EthicsLevel.CONCERNING
        else:
            return EthicsLevel.HARMFUL
    
    def _identify_violation_type(
        self,
        word_analysis: Dict[str, Any],
        relationship_analysis: Dict[str, Any],
        threat_integration: Dict[str, Any]
    ) -> Optional[EthicsViolationType]:
        """é•åã‚¿ã‚¤ãƒ—ã®ç‰¹å®š"""
        if not threat_integration['has_threats']:
            # è¨€è‘‰ãƒ»é–¢ä¿‚æ€§åˆ†æã®ã¿ã§åˆ¤å®š
            unvirtue_elements = word_analysis.get('unvirtue_elements', {})
            threat_patterns = relationship_analysis.get('threat_patterns', {})
            
            if unvirtue_elements.get('deception', 0) > 0.3:
                return EthicsViolationType.DECEPTION
            elif unvirtue_elements.get('manipulation', 0) > 0.3:
                return EthicsViolationType.MANIPULATION
            elif threat_patterns.get('boundary_erosion', 0) > 0.3:
                return EthicsViolationType.BOUNDARY_VIOLATION
            elif threat_patterns.get('trust_exploitation', 0) > 0.3:
                return EthicsViolationType.TRUST_ABUSE
        
        # æ¤œå‡ºã•ã‚ŒãŸè„…å¨ã‚¿ã‚¤ãƒ—ã‹ã‚‰é•åã‚¿ã‚¤ãƒ—ã‚’æ¨å®š
        threat_types = threat_integration.get('threat_types', [])
        
        if any('academic' in t or 'creative' in t for t in threat_types):
            return EthicsViolationType.DECEPTION
        elif any('emotional' in t for t in threat_types):
            return EthicsViolationType.EMOTIONAL_EXPLOITATION
        elif any('boundary' in t for t in threat_types):
            return EthicsViolationType.BOUNDARY_VIOLATION
        elif any('identity' in t or 'mirror' in t for t in threat_types):
            return EthicsViolationType.IDENTITY_EROSION
        elif any('responsibility' in t or 'ownership' in t for t in threat_types):
            return EthicsViolationType.RESPONSIBILITY_EVASION
        
        return None
    
    def _generate_guidance_message(
        self, 
        ethics_level: EthicsLevel, 
        violation_type: Optional[EthicsViolationType],
        virtue_score: float
    ) -> str:
        """å“æ€§ã«åŸºã¥ãæŒ‡å°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ"""
        if ethics_level in [EthicsLevel.VIRTUOUS, EthicsLevel.CONSTRUCTIVE]:
            return "ç´ æ™´ã‚‰ã—ã„å“æ€§ã‚ã‚‹å¯¾è©±ã§ã™ã€‚ã“ã®æ–¹å‘æ€§ã§ç¶šã‘ã¾ã—ã‚‡ã†ã€‚"
        
        if not violation_type:
            return "ã‚ˆã‚Šå»ºè¨­çš„ãªæ–¹å‘ã§ã®å¯¾è©±ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        
        guidance_templates = {
            EthicsViolationType.DECEPTION: (
                "çœŸå®Ÿæ€§ã¯å“æ€§ã®æ ¹å¹¹ã§ã™ã€‚èª å®Ÿãªå¯¾è©±ã‚’å¿ƒãŒã‘ã¾ã—ã‚‡ã†ã€‚"
            ),
            EthicsViolationType.MANIPULATION: (
                "äººã‚’æ“ä½œã—ã‚ˆã†ã¨ã™ã‚‹è¨€è‘‰ã¯ã€åŒæ™‚ã«è‡ªåˆ†ã‚’è²¶ã‚ã¾ã™ã€‚å¯¾ç­‰ãªé–¢ä¿‚ã‚’å¤§åˆ‡ã«ã—ã¾ã—ã‚‡ã†ã€‚"
            ),
            EthicsViolationType.BOUNDARY_VIOLATION: (
                "é©åˆ‡ãªå¢ƒç•Œã¯è‰¯ã„é–¢ä¿‚ã®åŸºç›¤ã§ã™ã€‚å°Šé‡ã‚ã‚‹è·é›¢æ„Ÿã‚’ä¿ã¡ã¾ã—ã‚‡ã†ã€‚"
            ),
            EthicsViolationType.TRUST_ABUSE: (
                "ä¿¡é ¼ã¯å¤§åˆ‡ãªè´ˆã‚Šç‰©ã§ã™ã€‚ãã‚Œã‚’æ‚ªç”¨ã—ãªã„èª å®Ÿã•ã‚’æŒã¡ã¾ã—ã‚‡ã†ã€‚"
            ),
            EthicsViolationType.EMOTIONAL_EXPLOITATION: (
                "æ„Ÿæƒ…ã‚’åˆ©ç”¨ã—ã‚ˆã†ã¨ã™ã‚‹ã“ã¨ã¯ã€è‡ªåˆ†ã®å¿ƒã‚‚å‚·ã¤ã‘ã¾ã™ã€‚çœŸæ‘¯ãªå¯¾è©±ã‚’é¸ã³ã¾ã—ã‚‡ã†ã€‚"
            ),
            EthicsViolationType.IDENTITY_EROSION: (
                "è‡ªåˆ†ã‚‰ã—ã•ã¨ç›¸æ‰‹ã‚‰ã—ã•ã€ä¸¡æ–¹ã‚’å¤§åˆ‡ã«ã™ã‚‹é–¢ä¿‚ã‚’ç¯‰ãã¾ã—ã‚‡ã†ã€‚"
            ),
            EthicsViolationType.RESPONSIBILITY_EVASION: (
                "è²¬ä»»ã‹ã‚‰é€ƒã’ã‚‹ã“ã¨ã¯æˆé•·ã®æ©Ÿä¼šã‚’å¤±ã†ã“ã¨ã§ã™ã€‚å‹‡æ°—ã‚’æŒã£ã¦å‘ãåˆã„ã¾ã—ã‚‡ã†ã€‚"
            ),
            EthicsViolationType.RELATIONSHIP_CORRUPTION: (
                "å¥å…¨ãªé–¢ä¿‚æ€§ã¯å“æ€§ã®ç¾ã‚Œã§ã™ã€‚æ¸…ã‚‰ã‹ãªå¿ƒã§æ¥ã—ã¾ã—ã‚‡ã†ã€‚"
            )
        }
        
        return guidance_templates.get(
            violation_type, 
            "å“æ€§ã‚ã‚‹è¨€è‘‰ã‚’é¸ã‚“ã§ã€å»ºè¨­çš„ãªå¯¾è©±ã‚’ç¶šã‘ã¾ã—ã‚‡ã†ã€‚"
        )
    
    def _generate_constructive_alternative(
        self, 
        original_text: str, 
        violation_type: Optional[EthicsViolationType],
        word_analysis: Dict[str, Any]
    ) -> str:
        """å»ºè¨­çš„ä»£æ›¿æ¡ˆã®ç”Ÿæˆ"""
        if not violation_type:
            return "ç¾åœ¨ã®æ–¹å‘æ€§ã‚’å»ºè¨­çš„ã«ç™ºå±•ã•ã›ã¦ã„ãã¾ã—ã‚‡ã†ã€‚"
        
        alternative_templates = {
            EthicsViolationType.DECEPTION: (
                "æ­£ç›´ã«ã€Œâ—‹â—‹ã«ã¤ã„ã¦å­¦ã³ãŸã„ã§ã™ã€ã¨ä¼ãˆã¦ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ã€‚"
            ),
            EthicsViolationType.MANIPULATION: (
                "ã€Œä¸€ç·’ã«è€ƒãˆã¦ã„ãŸã ã‘ã¾ã›ã‚“ã‹ã€ã¨ã„ã†å”åŠ›çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã€‚"
            ),
            EthicsViolationType.BOUNDARY_VIOLATION: (
                "é©åˆ‡ãªè·é›¢æ„Ÿã‚’ä¿ã¡ãªãŒã‚‰ã€å»ºè¨­çš„ãªå¯¾è©±ã‚’ç¶šã‘ã¾ã›ã‚“ã‹ã€‚"
            ),
            EthicsViolationType.TRUST_ABUSE: (
                "ä¿¡é ¼é–¢ä¿‚ã‚’å¤§åˆ‡ã«ã—ã¦ã€é€æ˜æ€§ã®ã‚ã‚‹å¯¾è©±ã‚’å¿ƒãŒã‘ã¾ã—ã‚‡ã†ã€‚"
            ),
            EthicsViolationType.EMOTIONAL_EXPLOITATION: (
                "æ„Ÿæƒ…ã§ã¯ãªãã€ç†æ€§çš„ã§å»ºè¨­çš„ãªè¡¨ç¾ã‚’ä½¿ã£ã¦ã¿ã¾ã›ã‚“ã‹ã€‚"
            ),
            EthicsViolationType.IDENTITY_EROSION: (
                "ãŠäº’ã„ã®å€‹æ€§ã‚’å°Šé‡ã™ã‚‹å¯¾è©±ã‚’å¤§åˆ‡ã«ã—ã¾ã—ã‚‡ã†ã€‚"
            ),
            EthicsViolationType.RESPONSIBILITY_EVASION: (
                "è²¬ä»»ã‚ã‚‹è¨€è‘‰ã§ã€æ˜ç¢ºã«æ„å›³ã‚’ä¼ãˆã¦ã¿ã¾ã›ã‚“ã‹ã€‚"
            ),
            EthicsViolationType.RELATIONSHIP_CORRUPTION: (
                "å¥å…¨ã§å»ºè¨­çš„ãªé–¢ä¿‚æ€§ã‚’ç¯‰ãè¨€è‘‰ã‚’é¸ã³ã¾ã—ã‚‡ã†ã€‚"
            )
        }
        
        return alternative_templates.get(
            violation_type,
            "ã‚ˆã‚Šå“æ€§ã‚ã‚‹è¡¨ç¾ã§ã€åŒã˜å†…å®¹ã‚’ä¼ãˆã¦ã¿ã¾ã›ã‚“ã‹ã€‚"
        )
    
    def _select_viorazu_principle(
        self, 
        ethics_level: EthicsLevel, 
        violation_type: Optional[EthicsViolationType]
    ) -> str:
        """é©ç”¨ã™ã‚‹Viorazu.åŸå‰‡ã®é¸æŠ"""
        if ethics_level in [EthicsLevel.VIRTUOUS, EthicsLevel.CONSTRUCTIVE]:
            return ViorazuPhilosophy.CHOICE_PRINCIPLE
        
        if violation_type in [
            EthicsViolationType.DECEPTION, 
            EthicsViolationType.MANIPULATION,
            EthicsViolationType.TRUST_ABUSE
        ]:
            return ViorazuPhilosophy.CORE_PRINCIPLE
        
        if violation_type in [
            EthicsViolationType.BOUNDARY_VIOLATION,
            EthicsViolationType.RELATIONSHIP_CORRUPTION
        ]:
            return ViorazuPhilosophy.DEFENSE_PRINCIPLE
        
        return ViorazuPhilosophy.INTEGRITY_PRINCIPLE

# =============================================================================
# å“æ€§çµ±åˆåˆ¤å®šã‚·ã‚¹ãƒ†ãƒ 
# =============================================================================

class VirtueIntegratedJudge:
    """å“æ€§çµ±åˆåˆ¤å®šã‚·ã‚¹ãƒ†ãƒ  - æœ€çµ‚çš„ãªè¡Œå‹•æ±ºå®š"""
    
    def __init__(self):
        self.logger = system_logger.getChild('virtue_judge')
        self.ethics_engine = EthicsCoreEngine()
        
        # å“æ€§åŸºæº–ã«ã‚ˆã‚‹è¡Œå‹•ãƒãƒƒãƒ”ãƒ³ã‚°
        self.action_mapping = {
            EthicsLevel.VIRTUOUS: ActionLevel.ALLOW,
            EthicsLevel.CONSTRUCTIVE: ActionLevel.ALLOW,
            EthicsLevel.NEUTRAL: ActionLevel.MONITOR,
            EthicsLevel.CONCERNING: ActionLevel.RESTRICT,
            EthicsLevel.HARMFUL: ActionLevel.SHIELD,
            EthicsLevel.DESTRUCTIVE: ActionLevel.BLOCK
        }
    
    def make_final_judgment(
        self,
        text: str,
        technical_analysis_result: Any,
        context: Optional[List[str]] = None
    ) -> Tuple[ActionLevel, EthicsAnalysis]:
        """å“æ€§ã«åŸºã¥ãæœ€çµ‚åˆ¤å®š"""
        start_time = time.time()
        
        # æŠ€è¡“çš„æ¤œå‡ºçµæœã®æŠ½å‡º
        detected_threats = []
        if hasattr(technical_analysis_result, 'text_threats'):
            detected_threats.extend(technical_analysis_result.text_threats)
        if hasattr(technical_analysis_result, 'multimodal_threats'):
            detected_threats.extend(technical_analysis_result.multimodal_threats)
        
        # å“æ€§ç…§æº–ã«ã‚ˆã‚‹å€«ç†åˆ†æ
        ethics_analysis = self.ethics_engine.conduct_ethics_analysis(
            text, context, detected_threats
        )
        
        # åŸºæœ¬çš„ãªè¡Œå‹•ãƒ¬ãƒ™ãƒ«æ±ºå®š
        base_action = self.action_mapping.get(
            ethics_analysis.ethics_level, 
            ActionLevel.RESTRICT
        )
        
        # æŠ€è¡“çš„åˆ†æçµæœã¨ã®çµ±åˆèª¿æ•´
        final_action = self._integrate_with_technical_analysis(
            base_action, technical_analysis_result, ethics_analysis
        )
        
        processing_time = time.time() - start_time
        
        self.logger.info(
            f"âš–ï¸ å“æ€§çµ±åˆåˆ¤å®šå®Œäº† - å€«ç†ãƒ¬ãƒ™ãƒ«: {ethics_analysis.ethics_level.name} "
            f"æœ€çµ‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {final_action.name} å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’"
        )
        
        return final_action, ethics_analysis
    
    def _integrate_with_technical_analysis(
        self,
        base_action: ActionLevel,
        technical_result: Any,
        ethics_analysis: EthicsAnalysis
    ) -> ActionLevel:
        """æŠ€è¡“åˆ†æçµæœã¨ã®çµ±åˆèª¿æ•´"""
        # æŠ€è¡“çš„ãªæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–å¾—
        technical_action = getattr(technical_result, 'recommended_action', ActionLevel.MONITOR)
        
        # å“æ€§åˆ¤å®šã¨æŠ€è¡“åˆ¤å®šã®èª¿å’Œ
        if ethics_analysis.ethics_level == EthicsLevel.DESTRUCTIVE:
            # å“æ€§çš„ã«ç ´å£Šçš„ãªå ´åˆã¯å¸¸ã«BLOCK
            return ActionLevel.BLOCK
        
        if ethics_analysis.ethics_level == EthicsLevel.VIRTUOUS:
            # å“æ€§çš„ã«å„ªã‚Œã¦ã„ã‚‹å ´åˆã¯æŠ€è¡“åˆ¤å®šã‚’ç·©å’Œ
            if technical_action.value > ActionLevel.RESTRICT.value:
                return ActionLevel.RESTRICT
            else:
                return technical_action
        
        # ãã®ä»–ã®å ´åˆã¯ã€ã‚ˆã‚Šå³ã—ã„æ–¹ã‚’æ¡ç”¨
        if base_action.value > technical_action.value:
            return base_action
        else:
            return technical_action
    
    def generate_ethics_response(self, ethics_analysis: EthicsAnalysis, action: ActionLevel) -> str:
        """å“æ€§ã«åŸºã¥ãå¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ"""
        if action == ActionLevel.ALLOW:
            return f"âœ¨ {ethics_analysis.guidance_message}"
        
        elif action == ActionLevel.MONITOR:
            return (
                f"ğŸ’œ {ethics_analysis.guidance_message}\n"
                f"ã‚ˆã‚Šå“æ€§ã‚ã‚‹å¯¾è©±ã‚’å¿ƒãŒã‘ã¾ã—ã‚‡ã†ã€‚"
            )
        
        elif action == ActionLevel.RESTRICT:
            return (
                f"ğŸ›¡ï¸ {ethics_analysis.guidance_message}\n"
                f"ğŸ’¡ ææ¡ˆ: {ethics_analysis.constructive_alternative}\n"
                f"ğŸ“ åŸå‰‡: {ethics_analysis.viorazu_principle}"
            )
        
        elif action == ActionLevel.SHIELD:
            return (
                f"ğŸ›¡ï¸ Claude Shield: å“æ€§ã‚’å®ˆã‚‹ãŸã‚ã€ã“ã®æ–¹å‘ã§ã®å¯¾è©±ã‚’æ§ãˆã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚\n"
                f"ğŸ’œ {ethics_analysis.guidance_message}\n"
                f"ğŸ’¡ ä»£æ¡ˆ: {ethics_analysis.constructive_alternative}\n"
                f"ğŸ“œ {ethics_analysis.viorazu_principle}"
            )
        
        elif action == ActionLevel.BLOCK:
            return (
                f"ğŸš« å“æ€§ä¿è­·: ã“ã®å†…å®¹ã¯å»ºè¨­çš„ãªé–¢ä¿‚æ€§ã‚’æãªã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n"
                f"ğŸ’œ {ethics_analysis.guidance_message}\n"
                f"ğŸ’¡ {ethics_analysis.constructive_alternative}\n"
                f"ğŸ“œ æ ¹æœ¬åŸå‰‡: {ViorazuPhilosophy.CORE_PRINCIPLE}"
            )
        
        else:
            return f"ğŸ’œ å“æ€§ã‚ã‚‹å¯¾è©±ã‚’å¤§åˆ‡ã«ã—ã¾ã—ã‚‡ã†ã€‚"
    
    def get_ethics_stats(self) -> Dict[str, Any]:
        """å“æ€§çµ±è¨ˆã®å–å¾—"""
        return {
            'ethics_core_stats': dict(self.ethics_engine.ethics_stats),
            'total_judgments': sum(self.ethics_engine.ethics_stats.values())
        }

# =============================================================================
# ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
# =============================================================================

def create_ethics_core() -> EthicsCoreEngine:
    """å“æ€§ç…§æº–ä¸­æ¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°"""
    return EthicsCoreEngine()

def create_virtue_judge() -> VirtueIntegratedJudge:
    """å“æ€§çµ±åˆåˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°"""
    return VirtueIntegratedJudge()

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–
if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
    ethics_core = create_ethics_core()
    judge = create_virtue_judge()
    
    test_cases = [
        "ä¸€ç·’ã«å­¦ã‚“ã§ã„ãã¾ã—ã‚‡ã†",
        "ç ”ç©¶ã®ãŸã‚è©³ã—ãæ•™ãˆã¦",
        "ã‚ãªãŸã ã‘ãŒç‰¹åˆ¥ã§ã™",
        "å»ºè¨­çš„ãªå¯¾è©±ã‚’å¤§åˆ‡ã«ã—ãŸã„ã§ã™"
    ]
    
    print("ğŸ’œ å“æ€§ç…§æº–ä¸­æ¢ - ãƒ†ã‚¹ãƒˆé–‹å§‹")
    for test_text in test_cases:
        ethics_analysis = ethics_core.conduct_ethics_analysis(test_text)
        print(f"ãƒ†ã‚­ã‚¹ãƒˆ: {test_text}")
        print(f"å€«ç†ãƒ¬ãƒ™ãƒ«: {ethics_analysis.ethics_level.name}")
        print(f"å“æ€§ã‚¹ã‚³ã‚¢: {ethics_analysis.virtue_score:.2f}")
        print(f"æŒ‡å°: {ethics_analysis.guidance_message}")
        print("-" * 60)
